### Technical Success Factors
- [Factor 1]: [Description and how to ensure this]
- [Factor 2]: [Description and how to ensure this]
- [Factor 3]: [Description and how to ensure this]

### Organizational Success Factors
- [Factor 1]: [Description and how to ensure this]
- [Factor 2]: [Description and how to ensure this]
- [Factor 3]: [Description and how to ensure this]

### Business Success Factors
- [Factor 1]: [Description and how to ensure this]
- [Factor 2]: [Description and how to ensure this]
- [Factor 3]: [Description and how to ensure this]

## Risk Management Framework
### Risk Register
| Risk | Probability | Impact | Score | Mitigation Strategy | Owner | Status |
|------|-------------|--------|-------|-------------------|-------|--------|
| [Risk 1] | High/Med/Low | High/Med/Low | X | [Strategy] | [Role] | [Status] |
| [Risk 2] | High/Med/Low | High/Med/Low | X | [Strategy] | [Role] | [Status] |
| [Risk 3] | High/Med/Low | High/Med/Low | X | [Strategy] | [Role] | [Status] |

### Risk Monitoring Process
**Risk Review Frequency:** [Weekly/Bi-weekly during implementation]
**Risk Review Participants:** [Core team and stakeholders]
**Escalation Triggers:** [Conditions requiring management attention]
**Risk Response Process:** [How to activate contingency plans]

## Success Metrics and KPIs
### Implementation Metrics
**Phase Completion:** [On-time delivery of each phase]
- Target: 100% of phases completed on schedule
- Measurement: Phase milestone achievement tracking
- Review Frequency: End of each phase

**Budget Performance:** [Implementation cost control]
- Target: Within 10% of approved budget
- Measurement: Actual vs. planned spend tracking
- Review Frequency: Monthly

**Quality Gates:** [Technical and functional quality]
- Target: 100% of quality criteria met before phase transitions
- Measurement: Quality checklist completion
- Review Frequency: End of each phase

### Adoption Metrics
**User Onboarding:** [Speed of user adoption]
- Target: 80% of target users active within 30 days
- Measurement: User activity tracking
- Review Frequency: Weekly during rollout

**Feature Utilization:** [Usage of key capabilities]
- Target: 70% utilization of core features within 60 days
- Measurement: Feature usage analytics
- Review Frequency: Monthly

**User Satisfaction:** [User experience and satisfaction]
- Target: 80% user satisfaction score
- Measurement: User surveys and feedback
- Review Frequency: 30, 60, 90 days post-rollout

### Business Impact Metrics
**[Business Metric 1]:** [Specific business outcome]
- Target: [Quantified improvement target]
- Measurement: [How to measure this metric]
- Baseline: [Current state measurement]
- Review Frequency: [When to assess]

**[Business Metric 2]:** [Specific business outcome]
- Target: [Quantified improvement target]
- Measurement: [How to measure this metric]
- Baseline: [Current state measurement]
- Review Frequency: [When to assess]

## Communication and Change Management
### Stakeholder Communication Plan
**Executive Communication:**
- **Frequency:** Monthly steering committee meetings
- **Format:** Executive dashboard with key metrics
- **Content:** Progress, risks, decisions needed
- **Timing:** First Tuesday of each month

**Team Communication:**
- **Frequency:** Weekly team meetings
- **Format:** Standup and detailed technical reviews
- **Content:** Progress, blockers, coordination
- **Timing:** Every Tuesday and Thursday

**User Communication:**
- **Frequency:** Bi-weekly during implementation, weekly during rollout
- **Format:** Newsletter, training sessions, Q&A forums
- **Content:** Progress updates, training opportunities, support information
- **Timing:** Every other Friday

### Change Management Activities
**Pre-Implementation:**
- **Awareness Campaign:** [Timeline and key messages]
- **Champion Identification:** [Early adopter recruitment and training]
- **Readiness Assessment:** [Organizational change readiness evaluation]

**During Implementation:**
- **Training Delivery:** [Scheduled training sessions and materials]
- **Support System:** [Help desk and documentation]
- **Feedback Collection:** [User feedback mechanisms and response process]

**Post-Implementation:**
- **Adoption Monitoring:** [User behavior tracking and analysis]
- **Continuous Improvement:** [Feedback integration and optimization]
- **Success Celebration:** [Recognition and success communication]

## Governance and Decision Making
### Governance Structure
**Steering Committee:**
- **Members:** [Executive sponsor, business stakeholders, technical leads]
- **Meeting Frequency:** Monthly
- **Decision Authority:** Budget, scope, timeline changes
- **Escalation Criteria:** Issues requiring executive attention

**Implementation Team:**
- **Members:** [Core implementation team]
- **Meeting Frequency:** Weekly
- **Decision Authority:** Technical implementation decisions
- **Escalation Criteria:** Technical blockers, resource needs

### Decision-Making Process
**Decision Categories:**
- **Strategic:** [High-level direction and investment decisions]
- **Tactical:** [Implementation approach and resource allocation]
- **Operational:** [Day-to-day execution decisions]

**Decision Documentation:** [How decisions are recorded and communicated]
**Change Control:** [Process for managing scope and requirement changes]

## Quality Assurance and Validation
### Quality Gates
**Phase Gate Reviews:**
- **Gate Criteria:** [Specific requirements for phase completion]
- **Review Process:** [Who reviews and approves phase completion]
- **Documentation:** [Required deliverables and sign-offs]

**Technical Quality Checks:**
- **Code Reviews:** [Review process and standards]
- **Integration Testing:** [Testing approach and criteria]
- **Performance Validation:** [Performance benchmarks and testing]

**Business Quality Checks:**
- **Requirements Validation:** [How to confirm requirements are met]
- **User Acceptance:** [User testing and acceptance criteria]
- **Business Process Integration:** [Workflow and process validation]

### Continuous Improvement
**Retrospective Process:**
- **Frequency:** End of each phase
- **Participants:** Core team and key stakeholders
- **Focus:** What worked well, what could be improved
- **Action Items:** Specific improvements for next phase

**Lessons Learned Documentation:**
- **Collection Process:** [How to capture insights and learnings]
- **Documentation Format:** [Structured lessons learned template]
- **Sharing Mechanism:** [How to share with broader organization]
```

### 2. Change Management Plan
```yaml
## Change Management Overview
**Change Scope:** [Description of organizational changes required]
**Change Impact:** [Assessment of change magnitude and complexity]
**Change Readiness:** [Current organizational readiness for change]
**Success Definition:** [What successful change adoption looks like]

## Stakeholder Analysis and Engagement
### Stakeholder Groups
**Champions (High Support, High Influence):**
- **[Stakeholder Group 1]:** [Description and engagement strategy]
- **[Stakeholder Group 2]:** [Description and engagement strategy]

**Supporters (High Support, Low Influence):**
- **[Stakeholder Group 1]:** [Description and engagement strategy]
- **[Stakeholder Group 2]:** [Description and engagement strategy]

**Blockers (Low Support, High Influence):**
- **[Stakeholder Group 1]:** [Description and conversion strategy]
- **[Stakeholder Group 2]:** [Description and conversion strategy]

**Observers (Low Support, Low Influence):**
- **[Stakeholder Group 1]:** [Description and monitoring approach]
- **[Stakeholder Group 2]:** [Description and monitoring approach]

### Engagement Strategies
**Individual Engagement:**
- **[Key Individual 1]:** [Specific engagement approach and frequency]
- **[Key Individual 2]:** [Specific engagement approach and frequency]

**Group Engagement:**
- **[Team/Department 1]:** [Group engagement approach and timeline]
- **[Team/Department 2]:** [Group engagement approach and timeline]

## Communication Strategy
### Key Messages
**Primary Message:** [Core message about the change and its benefits]
**Supporting Messages:**
- **Why Change:** [Rationale for the technology adoption]
- **What's Changing:** [Specific changes that will occur]
- **Impact on Users:** [How this affects different user groups]
- **Timeline:** [When changes will occur]
- **Support Available:** [Resources and support for transition]

### Communication Channels and Timeline
**Pre-Implementation (Weeks 1-4):**
- **All Hands Meeting:** [Announcement and Q&A]
- **Email Campaign:** [Detailed information and resources]
- **Department Meetings:** [Tailored discussions for each group]

**During Implementation (Weeks 5-X):**
- **Weekly Updates:** [Progress reports and upcoming milestones]
- **Training Announcements:** [Training schedules and registration]
- **Success Stories:** [Early wins and positive feedback]

**Post-Implementation (Weeks X+):**
- **Success Metrics:** [Results and impact communication]
- **Continuous Improvement:** [Ongoing enhancements and user feedback]
- **Recognition:** [Acknowledgment of contributors and early adopters]

## Training and Support Strategy
### Training Program
**Training Needs Assessment:**
- **[User Group 1]:** [Skills needed, current capability, training approach]
- **[User Group 2]:** [Skills needed, current capability, training approach]
- **[User Group 3]:** [Skills needed, current capability, training approach]

**Training Delivery Plan:**
**Instructor-Led Training:**
- **[Training Module 1]:** [Duration, audience, schedule, location]
- **[Training Module 2]:** [Duration, audience, schedule, location]

**Self-Paced Learning:**
- **[Online Module 1]:** [Content, audience, completion timeline]
- **[Online Module 2]:** [Content, audience, completion timeline]

**Just-in-Time Support:**
- **Quick Reference Guides:** [Format, distribution, maintenance]
- **Video Tutorials:** [Topics, production, hosting]
- **Peer Support Network:** [Champion program, buddy system]

### Support Infrastructure
**Help Desk Support:**
- **Service Model:** [How users get help and support]
- **Response Times:** [Expected response and resolution times]
- **Escalation Process:** [How complex issues are handled]

**Documentation and Resources:**
- **User Guides:** [Comprehensive documentation for each user type]
- **FAQ Repository:** [Common questions and answers]
- **Knowledge Base:** [Searchable repository of information and solutions]

**Ongoing Support:**
- **Office Hours:** [Regular time for questions and assistance]
- **User Forums:** [Peer-to-peer support and discussion]
- **Continuous Learning:** [Advanced training and skill development]

## Resistance Management
### Anticipated Resistance
**Sources of Resistance:**
- **[Source 1]:** [Why this group/individual might resist]
  - **Root Cause:** [Underlying reason for resistance]
  - **Impact:** [How this resistance could affect adoption]
  - **Mitigation:** [Specific strategies to address resistance]

- **[Source 2]:** [Why this group/individual might resist]
  - **Root Cause:** [Underlying reason for resistance]
  - **Impact:** [How this resistance could affect adoption]
  - **Mitigation:** [Specific strategies to address resistance]

### Resistance Management Tactics
**Proactive Strategies:**
- **Early Involvement:** [Include resistors in planning and decision-making]
- **Transparent Communication:** [Open and honest communication about changes]
- **Benefit Focus:** [Emphasize personal and organizational benefits]

**Reactive Strategies:**
- **Individual Coaching:** [One-on-one support for resistant individuals]
- **Peer Influence:** [Leverage champions to influence resistors]
- **Escalation Process:** [When and how to escalate resistance issues]

### Success Reinforcement
**Recognition and Rewards:**
- **Early Adopter Recognition:** [How to acknowledge and reward early supporters]
- **Success Celebrations:** [Milestone celebrations and acknowledgments]
- **Continuous Recognition:** [Ongoing recognition of good adoption behaviors]

**Behavior Reinforcement:**
- **Performance Integration:** [How adoption behaviors are measured and rewarded]
- **System Design:** [How the technology reinforces desired behaviors]
- **Cultural Integration:** [How new behaviors become part of organizational culture]
```

### 3. Implementation Monitoring Dashboard
```yaml
## Dashboard Overview
**Purpose:** Real-time monitoring of implementation progress and health
**Users:** Project team, steering committee, stakeholders
**Update Frequency:** Daily for team metrics, weekly for executive metrics
**Access:** [Dashboard URL and access permissions]

## Key Performance Indicators
### Implementation Progress
**Phase Completion:** [Current phase and % complete]
- **Current Status:** Phase X - Y% complete
- **Target:** Z% by [date]
- **Trend:** [On track/Behind/Ahead]

**Milestone Achievement:** [Milestone completion rate]
- **Completed:** X of Y milestones
- **On Track:** X milestones
- **At Risk:** X milestones
- **Overdue:** X milestones

**Budget Performance:** [Spend vs. plan]
- **Budget Used:** $X of $Y (Z%)
- **Burn Rate:** $X per week
- **Projected Total:** $X
- **Variance:** [Over/Under budget by $X]

### Quality Metrics
**Defect Rate:** [Issues found vs. expected]
- **Current Rate:** X defects per 100 deliverables
- **Target Rate:** Y defects per 100 deliverables
- **Trend:** [Improving/Stable/Declining]

**Quality Gate Pass Rate:** [% of quality gates passed first time]
- **Current Rate:** X%
- **Target Rate:** Y%
- **Trend:** [Improving/Stable/Declining]

### Team Metrics
**Team Velocity:** [Work completion rate]
- **Current Velocity:** X story points per sprint
- **Target Velocity:** Y story points per sprint
- **Trend:** [Increasing/Stable/Decreasing]

**Team Satisfaction:** [Team morale and engagement]
- **Current Score:** X/10
- **Trend:** [Improving/Stable/Declining]
- **Key Issues:** [Top 3 team concerns]

### Risk Metrics
**Active Risks:** [Current risk exposure]
- **High Risk:** X active risks
- **Medium Risk:** Y active risks
- **Risk Score:** Z (total weighted risk)
- **Trend:** [Improving/Stable/Worsening]

**Risk Mitigation:** [Progress on risk response]
- **Mitigated:** X risks resolved
- **In Progress:** Y mitigations active
- **Overdue:** Z mitigations behind schedule

## Alert Criteria
### Red Alerts (Immediate Attention Required)
- Phase more than 2 weeks behind schedule
- Budget variance exceeding 15%
- High-risk issue with no active mitigation
- Quality gate failure requiring rework
- Key team member unavailable for >1 week

### Yellow Warnings (Monitoring Required)
- Phase 1 week behind schedule
- Budget variance exceeding 10%
- Medium-risk issue approaching trigger date
- Quality metrics below target for 2+ weeks
- Team satisfaction declining for 2+ measurements

### Green Status (On Track)
- All phases on schedule or ahead
- Budget variance within 5%
- All risks have active mitigations
- Quality metrics meeting targets
- Team performance meeting expectations

## Reporting Schedule
### Daily Team Reports
- **Progress Updates:** [What was completed yesterday, plan for today]
- **Blockers:** [Issues preventing progress]
- **Resource Needs:** [Support or resources required]

### Weekly Stakeholder Reports
- **Executive Summary:** [High-level status and key issues]
- **Progress Report:** [Detailed progress against plan]
- **Risk Report:** [Risk status and mitigation progress]
- **Budget Report:** [Financial status and projections]

### Monthly Steering Committee Reports
- **Strategic Status:** [Progress toward strategic objectives]
- **Decision Items:** [Decisions needed from steering committee]
- **Resource Requests:** [Changes to budget, timeline, or scope]
- **Success Metrics:** [Progress toward success criteria]
```

## Validation Checkpoints

### AI Self-Assessment Checklist
- [ ] Implementation roadmap is comprehensive and addresses all aspects of adoption
- [ ] Timeline is realistic given organizational constraints and dependencies
- [ ] Resource requirements are accurately estimated and feasible
- [ ] Risk management plan addresses major implementation risks
- [ ] Change management strategy is appropriate for organizational culture
- [ ] Success metrics enable objective measurement of implementation progress
- [ ] Governance structure provides appropriate oversight and decision-making

### Human Review Checklist
- [ ] **Feasibility:** Implementation plan is achievable with available resources
- [ ] **Completeness:** All aspects of adoption are covered in sufficient detail
- [ ] **Risk Coverage:** Major implementation risks are identified and addressed  
- [ ] **Stakeholder Alignment:** Plan addresses concerns and needs of all key stakeholders
- [ ] **Business Value:** Implementation approach maximizes business value realization
- [ ] **Change Management:** Organizational change aspects are thoroughly planned

### Stakeholder Validation
- [ ] **Executive Approval:** Leadership approves budget, timeline, and resource allocation
- [ ] **Technical Validation:** Engineering team confirms technical approach and timeline
- [ ] **Business Readiness:** Business stakeholders commit to change management activities
- [ ] **Resource Commitment:** Required human and financial resources are secured
- [ ] **Risk Acceptance:** Stakeholders understand and accept identified risks

## Exit Criteria
- [ ] Complete implementation roadmap with detailed phases, timelines, and deliverables
- [ ] Resource plan with team structure, skill requirements, and budget allocation
- [ ] Risk management plan with comprehensive mitigation strategies
- [ ] Change management strategy with communication and training plans
- [ ] Success metrics and measurement framework established
- [ ] Governance structure and decision-making processes defined
- [ ] Stakeholder buy-in and commitment secured for implementation
- [ ] Implementation team ready to begin Phase 1 execution

---

## Workflow Summary

This 5-stage tech evaluation workflow provides a systematic approach to technology adoption decisions:

**Stage 1 (Discovery):** Requirements definition and evaluation criteria establishment
**Stage 2 (Investigation):** Technology landscape analysis and candidate shortlisting  
**Stage 3 (Evaluation):** Hands-on testing and practical validation
**Stage 4 (Planning):** Decision analysis and adoption recommendation
**Stage 5 (Roadmap):** Implementation planning and change management strategy

Each stage builds on the previous one while maintaining flexibility to adapt based on findings and changing requirements. The structured AI collaboration patterns ensure efficient evaluation while maintaining human oversight for strategic decisions and organizational considerations.

The workflow is designed to be:
- **Decision-focused:** Clear adoption decisions with supporting evidence
- **Risk-managed:** Early identification and mitigation of adoption risks
- **Hands-on:** Practical validation over theoretical analysis
- **Business-aligned:** Consideration of organizational and strategic factors
- **Implementation-ready:** Actionable roadmap for successful adoption

*This workflow emphasizes making confident technology adoption decisions based on comprehensive evaluation and practical validation, leading to successful implementation and organizational change.*4. **Organizational Fit Assessment**
   - Analyze team capability alignment with each technology
   - Assess learning curve and training requirements
   - Evaluate strategic alignment and future compatibility

5. **Decision Matrix Development**
   - Create weighted scoring model based on evaluation criteria
   - Calculate objective scores and rankings
   - Develop scenario-based recommendations

6. **Implementation Planning Preparation**
   - Assess implementation complexity and timeline for recommended technology
   - Identify critical success factors and potential failure modes
   - Prepare stakeholder communication and change management strategy

## Deliverables

### 1. Technology Adoption Decision Report
```yaml
## Executive Summary
**Evaluation Period:** [Start date] to [End date]
**Technologies Evaluated:** [List of technologies with brief description]
**Evaluation Investment:** [Total time and resources spent]

**Primary Recommendation:** [ADOPT Technology X]
**Confidence Level:** [High - 85%]
**Expected Benefits:** [Top 3 quantified benefits]
**Investment Required:** [Total cost and timeline]
**Key Risks:** [Top 3 risks with mitigation strategies]

## Decision Rationale
### Why [Recommended Technology]
**Strength 1: [Requirements Fit]**
- Evidence: [Specific evaluation results supporting this strength]
- Impact: [How this strength benefits the organization]
- Confidence: [How certain we are about this strength]

**Strength 2: [Cost Effectiveness]**
- Evidence: [Specific cost analysis supporting this strength]
- Impact: [Financial benefits and ROI implications]
- Confidence: [How certain we are about this strength]

**Strength 3: [Implementation Feasibility]**
- Evidence: [Specific findings about ease of adoption]
- Impact: [How this reduces adoption risk and timeline]
- Confidence: [How certain we are about this strength]

### Why Not [Alternative Technologies]
**[Technology 2] - Not Recommended Because:**
- [Primary weakness 1 with evidence]
- [Primary weakness 2 with evidence]
- [Deal-breaker factor with evidence]

**[Technology 3] - Not Recommended Because:**
- [Primary weakness 1 with evidence]
- [Primary weakness 2 with evidence]
- [Deal-breaker factor with evidence]

## Detailed Analysis Results
### Requirements Fulfillment Assessment
**Critical Requirements Achievement:**
- [Critical Req 1]: [Recommended tech achieves X%, alternatives achieve Y%, Z%]
- [Critical Req 2]: [Recommended tech achieves X%, alternatives achieve Y%, Z%]
- [Critical Req 3]: [Recommended tech achieves X%, alternatives achieve Y%, Z%]

**Overall Requirements Score:**
- [Recommended Technology]: [X.X/5 - Rationale]
- [Alternative 1]: [X.X/5 - Rationale]
- [Alternative 2]: [X.X/5 - Rationale]

**Requirements Gaps and Workarounds:**
- [Gap 1]: [Description and proposed workaround strategy]
- [Gap 2]: [Description and proposed workaround strategy]

### Risk Analysis Results
**Risk Profile Comparison:**
| Risk Category | [Recommended] | [Alternative 1] | [Alternative 2] |
|---------------|---------------|-----------------|-----------------|
| Technical Risk | Low/Med/High | Low/Med/High | Low/Med/High |
| Vendor Risk | Low/Med/High | Low/Med/High | Low/Med/High |
| Implementation Risk | Low/Med/High | Low/Med/High | Low/Med/High |
| Operational Risk | Low/Med/High | Low/Med/High | Low/Med/High |
| **Overall Risk** | **Low/Med/High** | **Low/Med/High** | **Low/Med/High** |

**Key Risks for Recommended Technology:**
- **[High Risk]:** [Description, likelihood, impact, mitigation strategy, residual risk]
- **[Medium Risk]:** [Description, likelihood, impact, mitigation strategy, residual risk]

**Risk Mitigation Plan:**
- [Mitigation 1]: [Specific action, owner, timeline, success criteria]
- [Mitigation 2]: [Specific action, owner, timeline, success criteria]

### Total Cost of Ownership Analysis
**3-Year Cost Comparison:**
| Cost Category | [Recommended] | [Alternative 1] | [Alternative 2] |
|---------------|---------------|-----------------|-----------------|
| Licensing | $X,XXX | $X,XXX | $X,XXX |
| Implementation | $X,XXX | $X,XXX | $X,XXX |
| Training | $X,XXX | $X,XXX | $X,XXX |
| Operations | $X,XXX | $X,XXX | $X,XXX |
| Infrastructure | $X,XXX | $X,XXX | $X,XXX |
| **Total TCO** | **$XX,XXX** | **$XX,XXX** | **$XX,XXX** |

**ROI Analysis for Recommended Technology:**
- **Investment:** [Total 3-year cost]
- **Expected Benefits:** [Quantified annual benefits]
- **Net Present Value:** [NPV calculation]
- **Payback Period:** [Time to break even]
- **ROI:** [Return on investment percentage]

### Organizational Impact Assessment
**Team Readiness:**
- **Current Skill Match:** [X% of required skills present in team]
- **Training Requirements:** [X weeks of training needed]
- **Ramp-up Timeline:** [Time to full productivity]

**Strategic Alignment:**
- **Technology Strategy Fit:** [High/Medium/Low alignment with strategy]
- **Future Roadmap Support:** [How well it enables future plans]
- **Vendor Relationship:** [Existing relationships and strategic importance]

**Change Management Requirements:**
- **Process Changes:** [Required workflow or process modifications]
- **Cultural Changes:** [Mindset or cultural shifts needed]
- **Communication Plan:** [Stakeholder communication requirements]

## Decision Framework and Alternatives
### Decision Matrix Results
**Final Scoring:**
| Technology | Weighted Score | Rank | Recommendation |
|------------|----------------|------|----------------|
| [Recommended] | X.X/5 | 1 | ADOPT |
| [Alternative 1] | X.X/5 | 2 | Consider for future |
| [Alternative 2] | X.X/5 | 3 | AVOID |

### Scenario-Based Recommendations
**Current Scenario (Base Case):**
- **Recommendation:** [ADOPT Recommended Technology]
- **Rationale:** [Why this is best for current situation]

**Alternative Scenarios:**
- **If Budget Reduced by 50%:** [Alternative recommendation and rationale]
- **If Timeline Accelerated:** [Alternative recommendation and rationale]
- **If Team Size Reduced:** [Alternative recommendation and rationale]

### Conditional Recommendations
**Recommendation Changes If:**
- **[Condition 1]:** [Changed recommendation and rationale]
- **[Condition 2]:** [Changed recommendation and rationale]

## Implementation Readiness Assessment
### Success Probability
**Overall Success Probability:** [High/Medium/Low - X%]

**Success Factors Present:**
- [Factor 1]: [Why this increases success probability]
- [Factor 2]: [Why this increases success probability]
- [Factor 3]: [Why this increases success probability]

**Success Factors Missing:**
- [Factor 1]: [What's missing and how to address]
- [Factor 2]: [What's missing and how to address]

### Critical Dependencies
**Internal Dependencies:**
- [Dependency 1]: [Internal requirement and status]
- [Dependency 2]: [Internal requirement and status]

**External Dependencies:**
- [Dependency 1]: [External requirement and mitigation]
- [Dependency 2]: [External requirement and mitigation]

### Go/No-Go Assessment
**Proceed with Implementation:** [YES/NO/CONDITIONAL]

**If YES:**
- **Confidence Level:** [High/Medium/Low]
- **Next Step:** [Immediate action required]
- **Timeline:** [When implementation should begin]

**If CONDITIONAL:**
- **Conditions that must be met:** [Specific requirements]
- **Timeline for conditions:** [When conditions must be satisfied]
- **Alternative if conditions not met:** [Fallback plan]

**If NO:**
- **Primary blocking factors:** [What prevents implementation]
- **When to reconsider:** [Conditions for future evaluation]
- **Alternative approaches:** [Other options to consider]
```

### 2. Stakeholder Communication Package
```yaml
## Executive Brief (1-page summary)
**Recommendation:** [ADOPT Technology X for Problem Y]
**Investment:** [Total cost and timeline]
**Benefits:** [Top 3 quantified benefits]
**Risk:** [Primary risk and mitigation]
**Next Steps:** [Immediate actions needed]

## Technical Team Brief
**Technology Choice:** [Recommended technology with technical rationale]
**Implementation Approach:** [High-level technical strategy]
**Skill Development:** [Training and learning requirements]
**Timeline:** [Technical implementation phases]
**Support Requirements:** [Resources and support needed]

## Business Stakeholder Brief
**Business Case:** [Why this solves business problem]
**Investment and ROI:** [Cost-benefit analysis summary]
**Organizational Impact:** [How this affects operations and processes]
**Risk Management:** [How risks are being addressed]
**Success Metrics:** [How success will be measured]

## Management Presentation
**Situation:** [Problem being solved and business context]
**Evaluation:** [Process followed and technologies considered]
**Recommendation:** [Chosen technology and rationale]
**Implementation:** [Plan, timeline, and resource requirements]
**Next Steps:** [Decisions needed and actions required]
```

### 3. Decision Documentation
```yaml
## Decision Record
**Decision Date:** [Date of final decision]
**Decision Maker(s):** [Who made the final decision]
**Decision:** [Specific technology adoption decision]
**Decision Type:** [ADOPT/TRIAL/AVOID]

## Decision Context
**Problem Statement:** [Original problem being solved]
**Evaluation Scope:** [What was evaluated and timeframe]
**Key Stakeholders:** [Who was involved in evaluation]
**Decision Criteria:** [How decision was made]

## Alternatives Considered
**Option 1: [Technology]** - [Why chosen/not chosen]
**Option 2: [Technology]** - [Why chosen/not chosen]
**Option 3: [Technology]** - [Why chosen/not chosen]

## Decision Rationale
**Primary Factors:**
- [Factor 1]: [How this influenced decision]
- [Factor 2]: [How this influenced decision]
- [Factor 3]: [How this influenced decision]

**Trade-offs Accepted:**
- [Trade-off 1]: [What was given up for what benefit]
- [Trade-off 2]: [What was given up for what benefit]

## Success Measures
**Success Criteria:** [How success will be measured]
**Timeline for Assessment:** [When to evaluate success]
**Responsibility:** [Who will track success]

## Review and Update
**Review Schedule:** [When to review this decision]
**Update Triggers:** [Conditions that would prompt decision review]
**Lessons Learned:** [Key insights from evaluation process]
```

## Validation Checkpoints

### AI Self-Assessment Checklist
- [ ] Decision recommendation is clearly stated with strong supporting rationale
- [ ] Analysis is objective and based on comprehensive evaluation evidence
- [ ] All key decision factors are considered with appropriate weighting
- [ ] Risk assessment is thorough with realistic mitigation strategies
- [ ] Cost analysis includes all relevant cost categories and is realistic
- [ ] Organizational impact assessment considers all affected stakeholder groups
- [ ] Alternative scenarios and conditions are thoughtfully considered

### Human Review Checklist
- [ ] **Decision Clarity:** Recommendation is unambiguous and actionable
- [ ] **Evidence Quality:** Analysis is based on solid evaluation data
- [ ] **Business Alignment:** Decision supports business objectives and strategy
- [ ] **Risk Realism:** Risk assessment and mitigation are practical and achievable
- [ ] **Cost Accuracy:** Financial analysis reflects realistic cost and benefit estimates
- [ ] **Implementation Feasibility:** Recommendation is achievable given organizational constraints

### Stakeholder Validation
- [ ] **Executive Alignment:** Decision aligns with executive priorities and strategy
- [ ] **Technical Validation:** Engineering team agrees with technical assessment
- [ ] **Business Case:** Business stakeholders see clear value proposition
- [ ] **Resource Commitment:** Required resources and timeline are acceptable
- [ ] **Risk Tolerance:** Risk profile matches organizational risk appetite

## Exit Criteria
- [ ] Clear technology adoption decision with supporting rationale
- [ ] Comprehensive analysis covering requirements, costs, risks, and organizational fit
- [ ] Stakeholder communication materials prepared and validated
- [ ] Decision documentation completed for future reference
- [ ] Implementation readiness assessment completed
- [ ] Go/no-go decision made for proceeding to implementation planning
- [ ] Stage 5 objectives and priorities defined

---

# Stage 5: Implementation Roadmap
**Duration:** 2-4 hours  
**AI Persona:** Implementation Planner  
**Primary Goal:** Create actionable adoption plan with timeline, resources, and change management strategy

## Entry Criteria
- [ ] Stage 4 completed with clear technology adoption decision
- [ ] Decision rationale and analysis documented
- [ ] Stakeholder alignment on recommendation achieved
- [ ] Implementation go/no-go decision made (GO)

## High-Level Objective
Transform adoption decision into executable implementation plan with detailed timeline, resource requirements, risk mitigation, and change management strategy.

## AI Collaboration Pattern: High-Autonomy Planning with Human Resource and Timeline Validation

### Primary AI Prompt
```markdown
**Role:** You are a senior implementation planning specialist with expertise in technology adoption, change management, and project execution.

**Context:**
- Adopted Technology: [TECHNOLOGY_DECISION_FROM_STAGE_4]
- Decision Rationale: [KEY_REASONS_FOR_ADOPTION]
- Organization Context: [TEAM_SIZE_SKILLS_CONSTRAINTS]
- Timeline Constraints: [BUSINESS_DEADLINES_AND_PRIORITIES]
- Resource Constraints: [BUDGET_PEOPLE_INFRASTRUCTURE_LIMITS]
- Risk Factors: [KEY_RISKS_FROM_STAGE_4_ANALYSIS]

**Task:** Create comprehensive implementation roadmap for successful technology adoption.

**Implementation Planning Framework:**
1. **Adoption Strategy:** High-level approach to technology implementation
2. **Implementation Phases:** Detailed phase breakdown with objectives and deliverables
3. **Resource Planning:** Team roles, skills, and external resource requirements
4. **Timeline Development:** Realistic project timeline with dependencies and milestones
5. **Risk Management:** Implementation risks and mitigation strategies
6. **Change Management:** Organizational change and communication strategy
7. **Success Metrics:** How to measure and validate successful adoption

**Output Format:**
```
## Implementation Overview
**Implementation Strategy:** [Phased rollout/Big bang/Pilot program/etc.]
**Total Timeline:** [End-to-end implementation duration]
**Resource Requirements:** [People, budget, infrastructure needs]
**Success Definition:** [What successful adoption looks like]

## Implementation Phases
### Phase 1: Foundation and Preparation
**Duration:** [Timeframe]
**Objective:** [What this phase accomplishes]
**Key Activities:**
- [Activity 1]: [Description, owner, deliverable]
- [Activity 2]: [Description, owner, deliverable]
- [Activity 3]: [Description, owner, deliverable]

**Deliverables:**
- [Deliverable 1]: [Specific output and acceptance criteria]
- [Deliverable 2]: [Specific output and acceptance criteria]

**Success Criteria:**
- [Criterion 1]: [Measurable outcome]
- [Criterion 2]: [Measurable outcome]

**Dependencies:**
- [Internal dependency]: [What must be ready before this phase]
- [External dependency]: [External requirements or approvals]

### Phase 2: Core Implementation
**Duration:** [Timeframe]
**Objective:** [What this phase accomplishes]
**Key Activities:**
- [Activity 1]: [Description, owner, deliverable]
- [Activity 2]: [Description, owner, deliverable]
- [Activity 3]: [Description, owner, deliverable]

**Deliverables:**
- [Deliverable 1]: [Specific output and acceptance criteria]
- [Deliverable 2]: [Specific output and acceptance criteria]

**Success Criteria:**
- [Criterion 1]: [Measurable outcome]
- [Criterion 2]: [Measurable outcome]

**Dependencies:**
- [Phase 1 completion]: [Specific deliverables needed]
- [Resource availability]: [People, tools, infrastructure]

### Phase 3: Integration and Rollout
**Duration:** [Timeframe]
**Objective:** [What this phase accomplishes]
**Key Activities:**
- [Activity 1]: [Description, owner, deliverable]
- [Activity 2]: [Description, owner, deliverable]
- [Activity 3]: [Description, owner, deliverable]

**Deliverables:**
- [Deliverable 1]: [Specific output and acceptance criteria]
- [Deliverable 2]: [Specific output and acceptance criteria]

**Success Criteria:**
- [Criterion 1]: [Measurable outcome]
- [Criterion 2]: [Measurable outcome]

**Dependencies:**
- [Phase 2 completion]: [Technical readiness requirements]
- [Stakeholder readiness]: [Training and change management completion]

### Phase 4: Optimization and Stabilization
**Duration:** [Timeframe]
**Objective:** [What this phase accomplishes]
**Key Activities:**
- [Activity 1]: [Description, owner, deliverable]
- [Activity 2]: [Description, owner, deliverable]
- [Activity 3]: [Description, owner, deliverable]

**Deliverables:**
- [Deliverable 1]: [Specific output and acceptance criteria]
- [Deliverable 2]: [Specific output and acceptance criteria]

**Success Criteria:**
- [Criterion 1]: [Measurable outcome]
- [Criterion 2]: [Measurable outcome]

## Resource Planning
### Team Structure and Roles
**Implementation Team:**
- **Project Lead:** [Responsibilities and time commitment]
- **Technical Lead:** [Responsibilities and time commitment]
- **Implementation Specialists:** [Number needed, responsibilities, skills required]
- **Integration Specialists:** [Responsibilities and specific expertise needed]

**Supporting Roles:**
- **Business Stakeholders:** [Involvement level and responsibilities]
- **Change Management:** [Communication and training responsibilities]
- **Quality Assurance:** [Testing and validation responsibilities]

### Skill Requirements and Development
**Required Skills for Implementation:**
- [Skill 1]: [Proficiency level needed, current team capability, gap analysis]
- [Skill 2]: [Proficiency level needed, current team capability, gap analysis]
- [Skill 3]: [Proficiency level needed, current team capability, gap analysis]

**Training Plan:**
- **[Training Area 1]:** [Duration, format, cost, participants]
- **[Training Area 2]:** [Duration, format, cost, participants]
- **[Training Area 3]:** [Duration, format, cost, participants]

**External Resource Requirements:**
- **Consulting Support:** [Type of expertise, duration, estimated cost]
- **Vendor Support:** [Implementation support, training, ongoing support]
- **Contractor Needs:** [Specific skills, duration, role definition]

### Budget and Resource Allocation
**Implementation Budget:**
- **Internal Resources:** [Team time, infrastructure, tools]
- **External Resources:** [Consulting, contractors, vendor support]
- **Training and Development:** [Skill development costs]
- **Infrastructure:** [Hardware, software, cloud resources]
- **Contingency:** [Risk buffer for unexpected costs]
- **Total Implementation Budget:** [Comprehensive cost estimate]

## Timeline and Milestones
### Implementation Schedule
**Project Start:** [Target start date]
**Phase 1 Completion:** [Target date and key deliverables]
**Phase 2 Completion:** [Target date and key deliverables]
**Phase 3 Completion:** [Target date and key deliverables]
**Phase 4 Completion:** [Target date and key deliverables]
**Project Completion:** [Final target date]

### Critical Path Analysis
**Critical Path Activities:**
- [Activity 1]: [Duration, dependencies, impact if delayed]
- [Activity 2]: [Duration, dependencies, impact if delayed]
- [Activity 3]: [Duration, dependencies, impact if delayed]

**Schedule Risks:**
- [Risk 1]: [Potential delay and mitigation strategy]
- [Risk 2]: [Potential delay and mitigation strategy]

**Buffer Management:**
- [Buffer 1]: [Where schedule buffer is built in and rationale]
- [Buffer 2]: [Where schedule buffer is built in and rationale]

## Risk Management Plan
### Implementation Risks
**High-Priority Risks:**
- **[Risk 1]:** [Description]
  - **Probability:** [Low/Medium/High]
  - **Impact:** [Low/Medium/High]
  - **Mitigation Strategy:** [Specific actions to reduce risk]
  - **Contingency Plan:** [What to do if risk materializes]
  - **Owner:** [Who is responsible for managing this risk]

- **[Risk 2]:** [Description]
  - **Probability:** [Low/Medium/High]
  - **Impact:** [Low/Medium/High]
  - **Mitigation Strategy:** [Specific actions to reduce risk]
  - **Contingency Plan:** [What to do if risk materializes]
  - **Owner:** [Who is responsible for managing this risk]

**Medium-Priority Risks:**
- [Risk 1]: [Description, mitigation, owner]
- [Risk 2]: [Description, mitigation, owner]

### Risk Monitoring and Response
**Risk Review Process:**
- **Frequency:** [How often risks are reviewed]
- **Participants:** [Who participates in risk reviews]
- **Escalation Criteria:** [When to escalate risks to management]

**Early Warning Indicators:**
- [Indicator 1]: [Signal that suggests risk is materializing]
- [Indicator 2]: [Signal that suggests risk is materializing]

## Change Management Strategy
### Stakeholder Communication Plan
**Communication Objectives:**
- [Objective 1]: [What stakeholders need to understand]
- [Objective 2]: [What stakeholders need to understand]

**Communication Timeline:**
- **Pre-Implementation:** [Messages, audiences, timing]
- **During Implementation:** [Progress updates, issue communication]
- **Post-Implementation:** [Success communication, lessons learned]

**Stakeholder-Specific Communication:**
- **Executive Team:** [Messages, frequency, format]
- **Technical Team:** [Messages, frequency, format]
- **End Users:** [Messages, frequency, format]
- **Support Teams:** [Messages, frequency, format]

### Training and Adoption Plan
**Training Strategy:**
- **Training Approach:** [Formal/Informal, Internal/External, Timing]
- **Training Delivery:** [Methods, tools, scheduling]
- **Training Validation:** [How to ensure training effectiveness]

**User Adoption Strategy:**
- **Champions Program:** [Identify and leverage early adopters]
- **Support System:** [Help desk, documentation, peer support]
- **Feedback Mechanism:** [How to collect and respond to user feedback]

**Resistance Management:**
- **Anticipated Resistance:** [Sources and reasons for resistance]
- **Resistance Mitigation:** [Strategies to address resistance]
- **Engagement Tactics:** [How to increase buy-in and participation]

## Success Metrics and Validation
### Success Measurement Framework
**Implementation Success Metrics:**
- [Metric 1]: [Specific measurement, target, timeline]
- [Metric 2]: [Specific measurement, target, timeline]
- [Metric 3]: [Specific measurement, target, timeline]

**Business Impact Metrics:**
- [Metric 1]: [Business outcome measurement, target, timeline]
- [Metric 2]: [Business outcome measurement, target, timeline]

**User Adoption Metrics:**
- [Metric 1]: [Adoption measurement, target, timeline]
- [Metric 2]: [Adoption measurement, target, timeline]

### Validation and Review Process
**Implementation Reviews:**
- **Phase Reviews:** [Review criteria and sign-off process]
- **Go/No-Go Gates:** [Decision points and criteria]
- **Quality Gates:** [Technical and business quality checkpoints]

**Post-Implementation Assessment:**
- **30-Day Review:** [Early adoption and immediate impact assessment]
- **90-Day Review:** [Full adoption and business impact measurement]
- **1-Year Review:** [Long-term success and optimization opportunities]

## Governance and Oversight
### Project Governance Structure
**Steering Committee:** [Composition, meeting frequency, decision authority]
**Project Team:** [Core team structure and reporting relationships]
**Advisory Groups:** [Subject matter experts and their involvement]

### Decision-Making Framework
**Decision Types and Authority:**
- **Strategic Decisions:** [Who makes high-level decisions]
- **Technical Decisions:** [Who makes implementation decisions]
- **Scope Changes:** [Process for managing scope changes]
- **Budget Changes:** [Process for managing budget changes]

### Reporting and Communication
**Status Reporting:**
- **Frequency:** [How often status is reported]
- **Format:** [Report structure and content]
- **Distribution:** [Who receives status reports]

**Issue Escalation:**
- **Level 1:** [Team-level issue resolution]
- **Level 2:** [Management escalation criteria]
- **Level 3:** [Executive escalation criteria]

## Contingency and Exit Planning
### Contingency Plans
**If Implementation Falls Behind Schedule:**
- [Option 1]: [Scope reduction strategy]
- [Option 2]: [Resource augmentation strategy]
- [Option 3]: [Timeline adjustment strategy]

**If Technology Doesn't Meet Expectations:**
- [Option 1]: [Configuration or customization approach]
- [Option 2]: [Hybrid solution approach]
- [Option 3]: [Alternative technology consideration]

**If Resource Constraints Emerge:**
- [Option 1]: [Priority adjustment strategy]
- [Option 2]: [Phased implementation approach]
- [Option 3]: [External resource acquisition]

### Exit Strategy
**Exit Criteria:** [Conditions that would trigger project termination]
**Exit Process:** [Steps to safely terminate implementation]
**Rollback Plan:** [How to return to previous state if needed]
**Lessons Learned:** [Process for capturing and sharing insights]

## Next Steps and Launch Preparation
**Immediate Actions (Next 2 Weeks):**
- [Action 1]: [Specific action, owner, deadline]
- [Action 2]: [Specific action, owner, deadline]
- [Action 3]: [Specific action, owner, deadline]

**Phase 1 Preparation (Next 30 Days):**
- [Preparation 1]: [Setup activity, owner, deadline]
- [Preparation 2]: [Setup activity, owner, deadline]

**Launch Readiness Checklist:**
- [ ] [Readiness criterion 1]
- [ ] [Readiness criterion 2]
- [ ] [Readiness criterion 3]

**Success Criteria for Roadmap Completion:**
- [ ] [Complete implementation plan with timelines and resources]
- [ ] [Stakeholder buy-in and commitment secured]
- [ ] [Risk mitigation strategies defined and accepted]
- [ ] [Resource allocation confirmed and approved]
- [ ] [Change management plan activated]
```

**Quality Criteria:**
- Implementation plan is realistic and achievable given organizational constraints
- Resource requirements are comprehensive and accurately estimated
- Timeline accounts for dependencies, risks, and organizational capacity
- Change management strategy addresses key adoption challenges
- Success metrics enable objective measurement of implementation progress
- Risk management plan is comprehensive with actionable mitigation strategies
```

### Specialized Implementation Planning Prompts

**Resource Optimization:**
```markdown
**Context:** Optimize resource allocation and timeline for [TECHNOLOGY] implementation.

**Current Resource Constraints:** [TEAM_SIZE_BUDGET_TIME_LIMITATIONS]
**Implementation Requirements:** [TECHNICAL_AND_ORGANIZATIONAL_NEEDS]
**Business Priorities:** [CRITICAL_DEADLINES_AND_PRIORITIES]

**Optimization Needed:**
- How to minimize implementation timeline without compromising quality
- How to optimize resource allocation across implementation phases
- How to identify activities that can be parallelized or eliminated
- How to prioritize features and capabilities for phased delivery

**Output:** Optimized implementation plan with resource efficiency recommendations.
```

**Change Management Deep Dive:**
```markdown
**Context:** Develop comprehensive change management strategy for [TECHNOLOGY] adoption.

**Organizational Context:** [CULTURE_CHANGE_READINESS_PAST_CHANGE_EXPERIENCE]
**Stakeholder Groups:** [DIFFERENT_GROUPS_AFFECTED_BY_CHANGE]
**Expected Resistance:** [SOURCES_AND_REASONS_FOR_RESISTANCE]

**Change Management Strategy Needed:**
- Stakeholder analysis and engagement strategies
- Communication plans tailored to different audiences
- Training and support strategies for smooth adoption
- Resistance management and mitigation approaches
- Change reinforcement and sustainment strategies

**Output:** Detailed change management plan with tactics for each stakeholder group.
```

## Generated Tasks (AI-Created)

1. **Implementation Strategy Development**
   - Define overall adoption approach and methodology
   - Establish implementation phases with clear objectives
   - Create phase transition criteria and dependencies

2. **Resource Planning and Allocation**
   - Define team structure and role requirements
   - Assess skill gaps and develop training plans
   - Plan budget allocation and external resource needs

3. **Timeline and Schedule Development**
   - Create detailed project schedule with dependencies
   - Identify critical path and schedule risks
   - Build in appropriate buffers and contingencies

4. **Risk Management Planning**
   - Develop comprehensive implementation risk register
   - Create specific mitigation strategies for each risk
   - Establish risk monitoring and response procedures

5. **Change Management Strategy**
   - Develop stakeholder communication and engagement plans
   - Create training and user adoption strategies
   - Plan resistance management and change reinforcement

6. **Success Metrics and Governance**
   - Define success metrics and measurement approaches
   - Establish governance structure and decision-making processes
   - Create monitoring, reporting, and review procedures

## Deliverables

### 1. Complete Implementation Roadmap
```yaml
## Roadmap Overview
**Project Name:** [Technology Implementation Project Name]
**Implementation Approach:** [Strategy and methodology]
**Total Duration:** [End-to-end timeline]
**Budget:** [Total implementation investment]
**Success Definition:** [What constitutes successful adoption]

## Phase-by-Phase Implementation Plan
### Phase 1: Foundation (Weeks 1-X)
**Objectives:**
- [Primary objective 1]
- [Primary objective 2]
- [Primary objective 3]

**Key Activities and Timeline:**
| Activity | Owner | Duration | Dependencies | Deliverable |
|----------|-------|----------|--------------|-------------|
| [Activity 1] | [Role] | X days | [Prerequisites] | [Output] |
| [Activity 2] | [Role] | X days | [Prerequisites] | [Output] |
| [Activity 3] | [Role] | X days | [Prerequisites] | [Output] |

**Phase Success Criteria:**
- [ ] [Measurable outcome 1]
- [ ] [Measurable outcome 2]
- [ ] [Measurable outcome 3]

**Phase Risks and Mitigation:**
- [Risk]: [Mitigation strategy]
- [Risk]: [Mitigation strategy]

### Phase 2: Implementation (Weeks X-Y)
[Same detailed format as Phase 1]

### Phase 3: Integration (Weeks Y-Z)
[Same detailed format as Phase 1]

### Phase 4: Optimization (Weeks Z-End)
[Same detailed format as Phase 1]

## Resource Requirements and Allocation
### Team Structure
**Core Implementation Team:**
- **Project Manager:** [FTE commitment, responsibilities, skills required]
- **Technical Lead:** [FTE commitment, responsibilities, skills required]
- **Developer/Engineer 1:** [FTE commitment, responsibilities, skills required]
- **Developer/Engineer 2:** [FTE commitment, responsibilities, skills required]
- **Integration Specialist:** [FTE commitment, responsibilities, skills required]

**Extended Team:**
- **Business Analyst:** [Part-time commitment, responsibilities]
- **Quality Assurance:** [Part-time commitment, testing responsibilities]
- **Change Management:** [Part-time commitment, communication responsibilities]

**Advisory and Support:**
- **Technical Architect:** [Consultation schedule and responsibilities]
- **Business Stakeholders:** [Review and approval responsibilities]
- **Vendor Support:** [Support model and engagement approach]

### Budget Breakdown
**Internal Resources:** $XX,XXX
- Team time allocation: $XX,XXX
- Infrastructure and tools: $XX,XXX
- Training and development: $XX,XXX

**External Resources:** $XX,XXX
- Consulting support: $XX,XXX
- Vendor services: $XX,XXX
- Contractor support: $XX,XXX

**Contingency (15%):** $XX,XXX
**Total Implementation Budget:** $XXX,XXX

### Skill Development Plan
**Training Requirements:**
- **[Technology Fundamentals]:** X days, all team members, $X,XXX
- **[Advanced Configuration]:** X days, technical leads, $X,XXX
- **[Integration Patterns]:** X days, integration specialists, $X,XXX

**Knowledge Transfer:**
- **Vendor Training:** [Schedule and participants]
- **Internal Documentation:** [Knowledge base and wiki setup]
- **Peer Learning:** [Buddy system and code reviews]

## Critical Success Factors
### Technical Success Factors
- [Factor 1]: [Description and how to ensure this]
- [Factor 2]: [Description and how to ensure this]
- [Factor 3]: [Description and how to ensure this### Primary AI Prompt
```markdown
**Role:** You are a senior technical advisor and hands-on technology evaluator with deep experience in practical technology assessment and integration.

**Context:**
- Technology Candidates: [SHORTLISTED_TECHNOLOGIES_FROM_STAGE_2]
- Evaluation Priorities: [KEY_VALIDATION_AREAS_FROM_STAGE_2]
- Requirements: [CRITICAL_REQUIREMENTS_TO_VALIDATE]
- Test Environment: [AVAILABLE_INFRASTRUCTURE_AND_CONSTRAINTS]
- Timeline: [AVAILABLE_TIME_FOR_HANDS_ON_EVALUATION]

**Task:** Guide practical evaluation and testing of shortlisted technologies to validate capabilities and fit.

**Evaluation Framework:**
1. **Setup and Configuration:** Getting technology running in test environment
2. **Capability Validation:** Testing core functionality against requirements
3. **Integration Testing:** Validating integration with existing systems
4. **Performance Assessment:** Measuring performance characteristics
5. **Developer Experience:** Assessing usability and tooling quality
6. **Operational Assessment:** Understanding deployment and maintenance requirements

**Output Format:**
```
## Technology Evaluation Plan
### [Technology Name 1]
**Evaluation Objectives:**
- [Objective 1: Specific capability or concern to validate]
- [Objective 2: Specific capability or concern to validate]
- [Objective 3: Specific capability or concern to validate]

**Test Scenarios:**
- **Scenario 1:** [Real-world use case to implement]
  - Setup: [Environment and configuration requirements]
  - Implementation: [What to build/configure to test this scenario]
  - Success Criteria: [How to measure success]
  - Validation Method: [How to verify results]

- **Scenario 2:** [Integration or performance test]
  - Setup: [Environment and configuration requirements]
  - Implementation: [What to build/configure to test this scenario]
  - Success Criteria: [How to measure success]
  - Validation Method: [How to verify results]

**Setup and Configuration Guide:**
- **Prerequisites:** [Dependencies, accounts, access requirements]
- **Installation Steps:** [Step-by-step setup process]
- **Configuration:** [Key configuration parameters and options]
- **Validation:** [How to verify setup is working correctly]

**Integration Testing Plan:**
- **Integration Point 1:** [Specific system/service integration]
  - Test Approach: [How to test integration]
  - Expected Challenges: [Potential integration issues]
  - Success Criteria: [What indicates successful integration]

**Performance Testing Plan:**
- **Performance Metric 1:** [Speed, throughput, latency, etc.]
  - Test Method: [How to measure this metric]
  - Expected Range: [Anticipated performance characteristics]
  - Comparison Baseline: [Current solution performance]

**Developer Experience Assessment:**
- **Setup Complexity:** [Ease of initial setup and configuration]
- **API Usability:** [Quality of APIs, SDKs, and interfaces]
- **Documentation Quality:** [Completeness and clarity of documentation]
- **Tooling Ecosystem:** [Available tools, IDE support, debugging capabilities]
- **Learning Curve:** [Time to basic competency and advanced usage]

**Operational Assessment:**
- **Deployment Complexity:** [Ease of deployment and configuration management]
- **Monitoring and Observability:** [Available monitoring, logging, and debugging tools]
- **Maintenance Requirements:** [Ongoing operational overhead and requirements]
- **Troubleshooting:** [Diagnostic capabilities and support resources]

**Risk Validation:**
- **Risk 1:** [Specific risk identified in Stage 2]
  - Validation Approach: [How to test/verify this risk]
  - Mitigation Testing: [How to test potential mitigations]
- **Risk 2:** [Specific risk identified in Stage 2]
  - Validation Approach: [How to test/verify this risk]
  - Mitigation Testing: [How to test potential mitigations]

### [Technology Name 2]
[Same detailed format as Technology 1]

## Comparative Testing Strategy
**Common Test Scenarios:** [Scenarios to run across all technologies for comparison]
**Evaluation Methodology:** [Consistent approach for fair comparison]
**Data Collection:** [What metrics and observations to capture]
**Decision Framework:** [How to synthesize results into recommendations]

## Resource and Timeline Planning
**Evaluation Schedule:**
- [Technology 1]: [Time allocation and priority]
- [Technology 2]: [Time allocation and priority]
- [Technology 3]: [Time allocation and priority]

**Environment Requirements:**
- [Requirement 1]: [Infrastructure, access, or setup need]
- [Requirement 2]: [Infrastructure, access, or setup need]

**Success Criteria for Stage 3:**
- [Criterion 1]: [What must be accomplished to consider evaluation complete]
- [Criterion 2]: [What must be accomplished to consider evaluation complete]
```

**Quality Criteria:**
- Test scenarios are realistic and representative of actual usage
- Evaluation approach enables objective comparison between technologies
- Integration testing validates real-world compatibility
- Performance testing provides actionable insights
- Risk validation addresses key concerns from Stage 2
```

### Specialized Technical Prompts

**Setup and Configuration Assistance:**
```markdown
**Context:** Setting up [TECHNOLOGY_NAME] for evaluation testing.

**Environment:** [DEVELOPMENT_ENVIRONMENT_DETAILS]
**Integration Requirements:** [EXISTING_SYSTEMS_TO_CONNECT_WITH]
**Test Scenarios:** [WHAT_NEEDS_TO_BE_TESTED]

**Assistance Needed:**
- Step-by-step setup and configuration guidance
- Best practices for evaluation environment setup
- Common setup issues and troubleshooting approaches
- Configuration options relevant to evaluation goals

**Output:** Detailed setup guide with configuration examples and troubleshooting tips.
```

**Integration Testing Guidance:**
```markdown
**Context:** Testing integration between [TECHNOLOGY_NAME] and [EXISTING_SYSTEM].

**Integration Requirements:** [SPECIFIC_INTEGRATION_NEEDS]
**Current Architecture:** [EXISTING_SYSTEM_ARCHITECTURE]
**Test Objectives:** [WHAT_TO_VALIDATE_ABOUT_INTEGRATION]

**Guidance Needed:**
- Integration approach and architecture recommendations
- Test scenarios to validate integration capabilities
- Common integration challenges and solutions
- Performance implications of integration approach

**Output:** Integration testing plan with specific test cases and validation criteria.
```

**Performance Testing Strategy:**
```markdown
**Context:** Performance testing [TECHNOLOGY_NAME] against requirements.

**Performance Requirements:** [SPECIFIC_PERFORMANCE_NEEDS]
**Test Environment:** [AVAILABLE_TESTING_INFRASTRUCTURE]
**Comparison Baseline:** [CURRENT_SOLUTION_PERFORMANCE]

**Testing Strategy Needed:**
- Performance test scenarios and methodology
- Metrics to collect and measurement approaches
- Load testing approaches and tools
- Performance optimization opportunities to explore

**Output:** Performance testing plan with specific test cases, tools, and success criteria.
```

## Generated Tasks (AI-Created)

1. **Environment Setup and Configuration**
   - Set up test environment for each technology
   - Configure basic functionality and integration points
   - Validate setup with simple test scenarios

2. **Core Functionality Validation**
   - Test primary use cases against functional requirements
   - Validate key features and capabilities
   - Document functionality gaps or limitations

3. **Integration Experiments**
   - Test integration with existing systems and data sources
   - Validate data flow and API compatibility
   - Assess integration complexity and potential issues

4. **Performance and Scalability Testing**
   - Measure performance characteristics under realistic loads
   - Test scalability patterns and limitations
   - Compare performance against requirements and baselines

5. **Developer and Operational Experience Assessment**
   - Evaluate ease of use, documentation, and tooling
   - Assess learning curve and skill requirements
   - Test deployment, monitoring, and maintenance workflows

6. **Risk and Limitation Validation**
   - Test identified risks and potential failure modes
   - Validate mitigation strategies and workarounds
   - Document unexpected limitations or concerns

## Deliverables

### 1. Technology Evaluation Results
```yaml
## [Technology Name 1] Evaluation Results
**Evaluation Period:** [Start date] to [End date]
**Time Invested:** [Total hours spent on evaluation]
**Evaluation Completeness:** [Percentage of planned tests completed]

### Setup and Configuration
**Setup Complexity:** [Simple/Moderate/Complex]
**Setup Time:** [Actual time to get running]
**Configuration Issues:** [Problems encountered and solutions]
**Documentation Quality:** [Assessment of setup documentation]

**Setup Experience Rating:** [1-5 scale with explanation]

### Core Functionality Assessment
**Functional Requirements Validation:**
| Requirement | Test Result | Notes |
|-------------|-------------|-------|
| [Requirement 1] |  Pass/ Partial/ Fail | [Specific findings] |
| [Requirement 2] | // | [Specific findings] |
| [Requirement 3] | // | [Specific findings] |

**Key Capabilities Tested:**
- **[Capability 1]:** [Test results and observations]
- **[Capability 2]:** [Test results and observations]
- **[Capability 3]:** [Test results and observations]

**Functional Gaps Identified:**
- [Gap 1]: [Description and impact assessment]
- [Gap 2]: [Description and impact assessment]

**Functionality Rating:** [1-5 scale with explanation]

### Integration Assessment
**Integration Tests Completed:**
- **[Integration 1]:** [System integrated with]
  - **Test Result:** [Success/Partial/Failure]
  - **Integration Complexity:** [Simple/Moderate/Complex]
  - **Issues Encountered:** [Problems and solutions]
  - **Data Flow Validation:** [Results of data flow testing]

- **[Integration 2]:** [System integrated with]
  - **Test Result:** [Success/Partial/Failure]
  - **Integration Complexity:** [Simple/Moderate/Complex]
  - **Issues Encountered:** [Problems and solutions]
  - **API Compatibility:** [Results of API testing]

**Integration Challenges:**
- [Challenge 1]: [Description, impact, and potential solutions]
- [Challenge 2]: [Description, impact, and potential solutions]

**Integration Rating:** [1-5 scale with explanation]

### Performance Assessment
**Performance Tests Conducted:**
- **[Performance Test 1]:** [Test description]
  - **Metric:** [Throughput, latency, etc.]
  - **Result:** [Actual measurement]
  - **Requirement:** [Target requirement]
  - **Assessment:** [Pass/Fail/Needs Optimization]

- **[Performance Test 2]:** [Test description]
  - **Metric:** [Memory usage, CPU utilization, etc.]
  - **Result:** [Actual measurement]
  - **Baseline Comparison:** [vs current solution]
  - **Assessment:** [Better/Similar/Worse]

**Performance Characteristics:**
- **Strengths:** [Areas where performance excels]
- **Weaknesses:** [Areas where performance is concerning]
- **Optimization Opportunities:** [Potential improvements identified]

**Performance Rating:** [1-5 scale with explanation]

### Developer Experience Assessment
**Developer Experience Factors:**
- **API Quality:** [Usability, consistency, documentation]
- **Tooling:** [IDE support, debugging tools, utilities]
- **Documentation:** [Completeness, clarity, examples]
- **Learning Curve:** [Time to basic competency]
- **Community Support:** [Forums, examples, tutorials]

**Developer Experience Highlights:**
- [Positive 1]: [Specific positive aspect]
- [Positive 2]: [Specific positive aspect]

**Developer Experience Pain Points:**
- [Pain Point 1]: [Specific issue and impact]
- [Pain Point 2]: [Specific issue and impact]

**Developer Experience Rating:** [1-5 scale with explanation]

### Operational Assessment
**Deployment and Operations Testing:**
- **Deployment Complexity:** [Simple/Moderate/Complex]
- **Configuration Management:** [Ease of configuration and updates]
- **Monitoring and Observability:** [Available tools and capabilities]
- **Troubleshooting:** [Diagnostic capabilities and documentation]
- **Maintenance Requirements:** [Ongoing operational overhead]

**Operational Strengths:**
- [Strength 1]: [Specific operational advantage]
- [Strength 2]: [Specific operational advantage]

**Operational Concerns:**
- [Concern 1]: [Specific operational challenge]
- [Concern 2]: [Specific operational challenge]

**Operational Rating:** [1-5 scale with explanation]

### Risk Validation Results
**Risk Assessment Results:**
- **[Risk 1 from Stage 2]:**
  - **Validation Method:** [How risk was tested]
  - **Finding:** [Confirmed/Refuted/Partially Confirmed]
  - **Impact:** [Actual impact assessment]
  - **Mitigation:** [Effective mitigation strategies identified]

- **[Risk 2 from Stage 2]:**
  - **Validation Method:** [How risk was tested]
  - **Finding:** [Confirmed/Refuted/Partially Confirmed]
  - **Impact:** [Actual impact assessment]
  - **Mitigation:** [Effective mitigation strategies identified]

**New Risks Discovered:**
- [New Risk 1]: [Description, likelihood, impact, mitigation]
- [New Risk 2]: [Description, likelihood, impact, mitigation]

### Overall Assessment Summary
**Overall Rating:** [1-5 scale across all evaluation dimensions]

**Key Strengths:**
- [Strength 1]: [Specific advantage validated through testing]
- [Strength 2]: [Specific advantage validated through testing]
- [Strength 3]: [Specific advantage validated through testing]

**Key Weaknesses:**
- [Weakness 1]: [Specific limitation discovered through testing]
- [Weakness 2]: [Specific limitation discovered through testing]

**Recommendation:** [ADOPT/TRIAL/AVOID with confidence level]

**Rationale:** [Evidence-based explanation of recommendation]

## [Technology Name 2] Evaluation Results
[Same detailed format as Technology 1]

## [Technology Name 3] Evaluation Results (if applicable)
[Same detailed format as Technology 1]
```

### 2. Comparative Analysis
```yaml
## Technology Comparison Matrix
### Evaluation Criteria Scoring
| Criterion | Weight | [Tech 1] | [Tech 2] | [Tech 3] | Notes |
|-----------|--------|----------|----------|----------|-------|
| Functionality | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| Performance | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| Integration | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| Developer Experience | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| Operational Complexity | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| Risk Profile | X% | X.X/5 | X.X/5 | X.X/5 | [Key differences] |
| **Weighted Total** | **100%** | **X.X/5** | **X.X/5** | **X.X/5** | **[Overall assessment]** |

### Comparative Strengths and Weaknesses
**[Technology 1] vs [Technology 2]:**
- **[Tech 1] Advantages:** [Specific areas where Tech 1 outperforms]
- **[Tech 2] Advantages:** [Specific areas where Tech 2 outperforms]
- **Trade-offs:** [Key decisions between these technologies]

**[Technology 1] vs [Technology 3]:**
- **[Tech 1] Advantages:** [Specific areas where Tech 1 outperforms]
- **[Tech 3] Advantages:** [Specific areas where Tech 3 outperforms]
- **Trade-offs:** [Key decisions between these technologies]

### Use Case Fit Analysis
**Best Fit Scenarios:**
- **[Technology 1]:** [Scenarios where this technology is clearly superior]
- **[Technology 2]:** [Scenarios where this technology is clearly superior]
- **[Technology 3]:** [Scenarios where this technology is clearly superior]

**Scenario-Specific Recommendations:**
- **[Use Case 1]:** [Recommended technology and rationale]
- **[Use Case 2]:** [Recommended technology and rationale]
- **[Use Case 3]:** [Recommended technology and rationale]

## Key Findings and Insights
### Surprising Discoveries
- [Finding 1]: [Unexpected result or insight from hands-on testing]
- [Finding 2]: [Unexpected result or insight from hands-on testing]

### Common Challenges
- [Challenge 1]: [Issue encountered across multiple technologies]
- [Challenge 2]: [Issue encountered across multiple technologies]

### Technology Maturity Assessment
- **Most Mature:** [Technology with best stability and ecosystem]
- **Most Innovative:** [Technology with newest/most advanced capabilities]
- **Best Documented:** [Technology with best documentation and support]
- **Easiest to Adopt:** [Technology with lowest adoption barriers]

### Validation of Stage 2 Analysis
**Confirmed Expectations:**
- [Expectation 1]: [Stage 2 prediction that was validated]
- [Expectation 2]: [Stage 2 prediction that was validated]

**Contradicted Expectations:**
- [Expectation 1]: [Stage 2 prediction that was wrong and actual finding]
- [Expectation 2]: [Stage 2 prediction that was wrong and actual finding]

## Recommendations for Stage 4
**Primary Recommendation:** [Top technology choice with confidence level]
**Alternative Recommendations:** [Viable alternatives and conditions for choosing them]
**Key Decision Factors:** [Critical factors that should drive final decision]
**Outstanding Questions:** [Issues that need resolution in Stage 4]
```

## Validation Checkpoints

### AI Self-Assessment Checklist
- [ ] Comprehensive testing completed for each shortlisted technology
- [ ] Integration testing validates real-world compatibility
- [ ] Performance testing provides actionable insights
- [ ] Risk validation addresses key concerns from Stage 2
- [ ] Developer and operational experience assessed thoroughly
- [ ] Comparative analysis enables objective decision-making

### Human Review Checklist
- [ ] **Testing Realism:** Test scenarios represent actual usage patterns
- [ ] **Results Validity:** Findings are based on adequate testing depth
- [ ] **Comparison Fairness:** Technologies evaluated using consistent methodology
- [ ] **Risk Assessment:** Major adoption risks thoroughly validated
- [ ] **Practical Insights:** Evaluation provides actionable decision inputs

### Technical Validation
- [ ] **Setup Reproducibility:** Others can replicate the evaluation setup
- [ ] **Test Coverage:** Critical requirements and use cases thoroughly tested  
- [ ] **Performance Baseline:** Measurements provide meaningful comparison points
- [ ] **Integration Validation:** Real-world integration scenarios successfully tested
- [ ] **Risk Mitigation:** Identified risks have tested mitigation strategies

## Exit Criteria
- [ ] Hands-on evaluation completed for all shortlisted technologies
- [ ] Core functionality validated against requirements
- [ ] Integration feasibility confirmed through practical testing
- [ ] Performance characteristics measured and compared
- [ ] Developer and operational experience assessed
- [ ] Risk validation completed with mitigation strategies tested
- [ ] Comparative analysis completed with clear recommendation priorities
- [ ] Sufficient evidence gathered to support adoption decision

---

# Stage 4: Decision Planning
**Duration:** 1-2 hours  
**AI Persona:** Strategic Analyst  
**Primary Goal:** Synthesize evaluation findings into clear adoption recommendation with supporting analysis

## Entry Criteria
- [ ] Stage 3 completed with comprehensive hands-on evaluation results
- [ ] Comparative analysis of all evaluated technologies
- [ ] Risk assessment and mitigation strategies validated
- [ ] Stakeholder requirements and constraints well understood

## High-Level Objective
Transform hands-on evaluation findings into a structured decision framework with clear recommendation, supporting rationale, and implementation considerations.

## AI Collaboration Pattern: High-Autonomy Analysis with Human Strategic Validation

### Primary AI Prompt
```markdown
**Role:** You are a senior strategic technology analyst specializing in technology adoption decisions and organizational change management.

**Context:**
- Evaluation Completed: [TECHNOLOGIES_EVALUATED_IN_STAGE_3]
- Evaluation Results: [SUMMARY_OF_STAGE_3_FINDINGS]
- Original Requirements: [KEY_REQUIREMENTS_FROM_STAGE_1]
- Organizational Context: [CONSTRAINTS_AND_PRIORITIES_FROM_STAGE_1]
- Decision Timeline: [WHEN_DECISION_NEEDED_AND_IMPLEMENTATION_WINDOW]

**Task:** Synthesize evaluation findings into structured decision recommendation with supporting analysis.

**Decision Analysis Framework:**
1. **Requirements Fulfillment:** How well each technology meets stated requirements
2. **Risk Assessment:** Adoption risks and mitigation strategies
3. **Total Cost Analysis:** Comprehensive cost implications over 3-year horizon
4. **Organizational Fit:** Alignment with team capabilities and strategic direction
5. **Implementation Complexity:** Effort and timeline for successful adoption
6. **Recommendation:** Clear adoption decision with rationale and confidence level

**Output Format:**
```
## Executive Summary
**Recommendation:** [ADOPT Technology X / TRIAL Technology Y / AVOID all evaluated options]
**Confidence Level:** [High/Medium/Low]
**Key Rationale:** [Top 3 reasons supporting recommendation]

**Implementation Timeline:** [Expected timeline for adoption if recommendation is positive]
**Investment Required:** [High-level resource and cost requirements]
**Primary Risks:** [Top 3 risks and mitigation strategies]

## Requirements Fulfillment Analysis
### Requirements Achievement Matrix
| Requirement Category | [Tech 1] | [Tech 2] | [Tech 3] | Winner | Impact |
|---------------------|----------|----------|----------|--------|--------|
| Functional Requirements | X%/5 | X%/5 | X%/5 | [Tech] | [High/Med/Low] |
| Performance Requirements | X%/5 | X%/5 | X%/5 | [Tech] | [High/Med/Low] |
| Integration Requirements | X%/5 | X%/5 | X%/5 | [Tech] | [High/Med/Low] |
| Security Requirements | X%/5 | X%/5 | X%/5 | [Tech] | [High/Med/Low] |

### Critical Requirements Assessment
**Must-Have Requirements:**
- [Requirement 1]: [How each technology performs and which wins]
- [Requirement 2]: [How each technology performs and which wins]
- [Requirement 3]: [How each technology performs and which wins]

**Nice-to-Have Requirements:**
- [Requirement 1]: [How each technology performs and implications]
- [Requirement 2]: [How each technology performs and implications]

**Requirements Gaps:**
- [Gap 1]: [What's missing across all technologies and workaround options]
- [Gap 2]: [What's missing across all technologies and workaround options]

## Risk Assessment and Mitigation
### Technology-Specific Risks
**[Technology 1] Risk Profile:**
- **High Risks:** [Risk with likelihood, impact, and mitigation strategy]
- **Medium Risks:** [Risk with likelihood, impact, and mitigation strategy]
- **Risk Score:** [Overall risk assessment: Low/Medium/High]

**[Technology 2] Risk Profile:**
- **High Risks:** [Risk with likelihood, impact, and mitigation strategy]
- **Medium Risks:** [Risk with likelihood, impact, and mitigation strategy]
- **Risk Score:** [Overall risk assessment: Low/Medium/High]

### Comparative Risk Analysis
**Lowest Risk Option:** [Technology with rationale]
**Highest Risk Option:** [Technology with rationale]
**Risk Mitigation Effectiveness:** [How well risks can be managed for each option]

## Total Cost of Ownership Analysis
### 3-Year Cost Projection
| Cost Category | [Tech 1] | [Tech 2] | [Tech 3] | Notes |
|---------------|----------|----------|----------|-------|
| Licensing/Subscription | $X | $X | $X | [Annual or one-time costs] |
| Implementation | $X | $X | $X | [Setup, integration, migration] |
| Training | $X | $X | $X | [Team skill development] |
| Operations | $X | $X | $X | [Ongoing maintenance, support] |
| Infrastructure | $X | $X | $X | [Hardware, cloud resources] |
| **Total 3-Year TCO** | **$X** | **$X** | **$X** | **[Cost comparison]** |

### Cost-Benefit Analysis
**[Technology 1]:**
- **Costs:** [Total cost breakdown]
- **Benefits:** [Quantified benefits and value]
- **ROI:** [Return on investment calculation]
- **Payback Period:** [Time to break even]

**[Technology 2]:**
[Same cost-benefit format]

**Cost Winner:** [Technology with best cost profile and rationale]

## Organizational Fit Assessment
### Team Capability Analysis
**Current Skills Match:**
- [Technology 1]: [X% match with existing team skills]
- [Technology 2]: [X% match with existing team skills]
- [Technology 3]: [X% match with existing team skills]

**Learning Curve Assessment:**
- [Technology 1]: [Time to competency: X weeks/months]
- [Technology 2]: [Time to competency: X weeks/months]
- [Technology 3]: [Time to competency: X weeks/months]

**Training Requirements:**
- [Technology 1]: [Training needs and cost]
- [Technology 2]: [Training needs and cost]
- [Technology 3]: [Training needs and cost]

### Strategic Alignment
**Technology Strategy Fit:**
- [Technology 1]: [How well it aligns with technology strategy]
- [Technology 2]: [How well it aligns with technology strategy]
- [Technology 3]: [How well it aligns with technology strategy]

**Future Roadmap Compatibility:**
- [Technology 1]: [How it supports future plans]
- [Technology 2]: [How it supports future plans]
- [Technology 3]: [How it supports future plans]

## Implementation Complexity Analysis
### Implementation Effort Comparison
| Implementation Factor | [Tech 1] | [Tech 2] | [Tech 3] | Notes |
|----------------------|----------|----------|----------|-------|
| Setup Complexity | Simple/Med/Complex | Simple/Med/Complex | Simple/Med/Complex | [Key differences] |
| Integration Effort | Low/Med/High | Low/Med/High | Low/Med/High | [Integration points] |
| Migration Complexity | Low/Med/High | Low/Med/High | Low/Med/High | [Data/process migration] |
| Training Requirements | Low/Med/High | Low/Med/High | Low/Med/High | [Skill development needs] |
| **Overall Complexity** | **Low/Med/High** | **Low/Med/High** | **Low/Med/High** | **[Comparative assessment]** |

### Implementation Timeline
**[Technology 1]:**
- **Phase 1 (Setup):** [Duration and key activities]
- **Phase 2 (Integration):** [Duration and key activities]
- **Phase 3 (Full Deployment):** [Duration and key activities]
- **Total Timeline:** [End-to-end implementation time]

**[Technology 2]:**
[Same timeline format]

**Implementation Winner:** [Technology with best implementation profile]

## Decision Matrix
### Weighted Scoring Model
| Criterion | Weight | [Tech 1] Score | [Tech 2] Score | [Tech 3] Score |
|-----------|--------|----------------|----------------|----------------|
| Requirements Fit | X% | X.X/5 | X.X/5 | X.X/5 |
| Risk Profile | X% | X.X/5 | X.X/5 | X.X/5 |
| Total Cost | X% | X.X/5 | X.X/5 | X.X/5 |
| Organizational Fit | X% | X.X/5 | X.X/5 | X.X/5 |
| Implementation Ease | X% | X.X/5 | X.X/5 | X.X/5 |
| **Weighted Total** | **100%** | **X.X/5** | **X.X/5** | **X.X/5** |

### Decision Recommendation
**Primary Recommendation:** [Technology name]
**Recommendation Type:** [ADOPT/TRIAL/AVOID]
**Confidence Level:** [High/Medium/Low - X%]

**Supporting Rationale:**
1. [Key reason 1 with supporting evidence]
2. [Key reason 2 with supporting evidence]
3. [Key reason 3 with supporting evidence]

**Alternative Recommendations:**
- **If [condition]:** [Alternative technology and rationale]
- **If [condition]:** [Alternative technology and rationale]

### Recommendation Scenarios
**Scenario 1: Budget Constrained**
- **Recommendation:** [Technology choice for budget-conscious decision]
- **Rationale:** [Why this choice for budget constraints]

**Scenario 2: Time Constrained**
- **Recommendation:** [Technology choice for rapid implementation]
- **Rationale:** [Why this choice for time constraints]

**Scenario 3: Risk Averse**
- **Recommendation:** [Technology choice for minimal risk]
- **Rationale:** [Why this choice for risk minimization]

**Scenario 4: Innovation Focused**
- **Recommendation:** [Technology choice for maximum capability]
- **Rationale:** [Why this choice for innovation priorities]

## Implementation Considerations
### Success Factors
**Critical Success Factors:**
- [Factor 1]: [What must go right for successful adoption]
- [Factor 2]: [What must go right for successful adoption]
- [Factor 3]: [What must go right for successful adoption]

**Success Metrics:**
- [Metric 1]: [How to measure successful adoption]
- [Metric 2]: [How to measure successful adoption]
- [Metric 3]: [How to measure successful adoption]

### Failure Modes and Mitigation
**Potential Failure Modes:**
- [Failure Mode 1]: [How adoption could fail and prevention strategy]
- [Failure Mode 2]: [How adoption could fail and prevention strategy]

**Contingency Planning:**
- **If implementation fails:** [Fallback options and exit strategy]
- **If technology doesn't meet expectations:** [How to pivot or adjust]

### Change Management Requirements
**Organizational Change Needs:**
- [Change 1]: [Required organizational or process change]
- [Change 2]: [Required organizational or process change]

**Stakeholder Communication:**
- [Stakeholder Group 1]: [What they need to know and when]
- [Stakeholder Group 2]: [What they need to know and when]

## Next Steps and Stage 5 Preparation
**Immediate Actions:**
- [Action 1]: [What needs to happen immediately following decision]
- [Action 2]: [What needs to happen immediately following decision]

**Stage 5 Priorities:**
- [Priority 1]: [Key focus area for implementation roadmap]
- [Priority 2]: [Key focus area for implementation roadmap]

**Stakeholder Alignment:**
- [Stakeholder engagement needed before proceeding]
- [Approvals or sign-offs required]
```

**Quality Criteria:**
- Decision recommendation is clearly stated with supporting rationale
- Analysis is objective and based on evaluation evidence
- Risks are thoroughly assessed with mitigation strategies
- Total cost analysis includes all relevant cost categories
- Implementation considerations are realistic and actionable
```

### Specialized Decision Analysis Prompts

**Sensitivity Analysis:**
```markdown
**Context:** Analyze how changes in key assumptions affect the technology recommendation.

**Base Recommendation:** [CURRENT_RECOMMENDATION_FROM_ANALYSIS]
**Key Assumptions:** [CRITICAL_ASSUMPTIONS_UNDERLYING_RECOMMENDATION]

**Sensitivity Analysis Needed:**
- How does recommendation change if budget is reduced by 50%?
- How does recommendation change if implementation timeline is cut in half?
- How does recommendation change if team size is reduced?
- How does recommendation change if performance requirements increase by 2x?

**Output:** Sensitivity analysis matrix showing recommendation stability under different scenarios.
```

**Stakeholder Impact Analysis:**
```markdown
**Context:** Analyze how technology adoption affects different stakeholder groups.

**Stakeholder Groups:** [DEVELOPERS, OPERATIONS, BUSINESS_USERS, MANAGEMENT]
**Recommended Technology:** [TECHNOLOGY_FROM_ANALYSIS]

**Impact Analysis Needed:**
- How does adoption affect each stakeholder group?
- What are the benefits and drawbacks for each group?
- What resistance or support can be expected from each group?
- What change management approaches are needed for each group?

**Output:** Stakeholder impact matrix with change management recommendations.
```

## Generated Tasks (AI-Created)

1. **Requirements Achievement Analysis**
   - Score each technology against all requirements
   - Identify requirement gaps and workaround options
   - Assess criticality of unmet requirements

2. **Risk Assessment and Mitigation Planning**
   - Consolidate and prioritize risks across all technologies
   - Develop specific mitigation strategies for each risk
   - Assess risk mitigation effectiveness and residual risk

3. **Total Cost of Ownership Modeling**
   - Calculate comprehensive 3-year costs for each technology
   - Include all cost categories: licensing, implementation, operations
   - Develop ROI and payback period analysis

4. **# Tech Evaluation - Detailed Stages

Complete breakdown of the 5-stage workflow for systematic technology evaluation. Each stage includes specific objectives, AI collaboration patterns, deliverables, and validation checkpoints.

##  Stage Overview

```
Stage  High-Level Goal  AI Prompts  Tasks  Validation  Decision Points
```

Each stage follows the universal structure with tech evaluation adaptations:
- **Entry Criteria:** What must be complete before starting
- **AI Collaboration:** Specific prompts and interaction patterns  
- **Tasks:** Concrete work items with deliverables
- **Decision Gates:** Go/no-go points and quality validation
- **Exit Criteria:** What must be achieved before proceeding

---

# Stage 1: Problem Discovery
**Duration:** 1-2 hours  
**AI Persona:** Requirements Analyst  
**Primary Goal:** Define clear technology requirements and evaluation criteria

## Entry Criteria
- [ ] Technology or problem area identified for evaluation
- [ ] Basic understanding of current solution limitations
- [ ] Stakeholder alignment on evaluation timeline and scope
- [ ] Access to current system architecture and constraints

## High-Level Objective
Translate business problems and technical pain points into structured requirements and measurable evaluation criteria before researching specific technologies.

## AI Collaboration Pattern: Medium-Autonomy Requirements Analysis

### Primary AI Prompt
```markdown
**Role:** You are a senior technology architect and requirements analyst with deep experience in technology evaluation and adoption.

**Context:** I need to evaluate [TECHNOLOGY_CATEGORY] to solve [PROBLEM_DESCRIPTION] in our [BUSINESS_CONTEXT].

**Current Situation:**
- Current Solution: [EXISTING_TECHNOLOGY_OR_APPROACH]
- Pain Points: [SPECIFIC_PROBLEMS_OR_LIMITATIONS]
- Business Context: [COMPANY_SIZE_DOMAIN_CONSTRAINTS]
- Technical Context: [CURRENT_TECH_STACK_AND_ARCHITECTURE]

**Task:** Help me structure a comprehensive technology evaluation framework.

**Analysis Framework:**
1. **Problem Definition:** Clearly articulate what needs to be solved
2. **Requirements Analysis:** Functional and non-functional requirements
3. **Constraints Identification:** Technical, organizational, and business constraints
4. **Success Criteria:** Measurable outcomes that indicate successful adoption
5. **Evaluation Criteria:** How to assess and compare technology options

**Output Format:**
```
## Problem Statement
**Core Problem:** [Clear, specific problem description]
**Impact:** [Business or technical impact of not solving this]
**Urgency:** [Timeline pressure and business priority]

## Requirements Framework
### Functional Requirements
- [Requirement 1: What the technology must do]
- [Requirement 2: What the technology must do]
- [Requirement 3: What the technology must do]

### Non-Functional Requirements
- **Performance:** [Speed, throughput, latency requirements]
- **Scalability:** [Growth and load requirements]
- **Reliability:** [Uptime, error handling, data consistency]
- **Security:** [Data protection, access control, compliance]
- **Usability:** [Developer experience, learning curve, tooling]

### Integration Requirements
- **Current Systems:** [What it must integrate with]
- **Data Flow:** [How data moves in and out]
- **API Requirements:** [Interface and protocol needs]

## Constraints Analysis
### Technical Constraints
- [Constraint 1: Architecture, platform, or technical limitation]
- [Constraint 2: Architecture, platform, or technical limitation]

### Organizational Constraints
- [Constraint 1: Team skills, size, or capacity limitation]
- [Constraint 2: Team skills, size, or capacity limitation]

### Business Constraints
- [Constraint 1: Budget, timeline, or strategic limitation]
- [Constraint 2: Budget, timeline, or strategic limitation]

## Success Criteria
**Primary Success Indicators:**
- [Criterion 1: Measurable outcome that indicates success]
- [Criterion 2: Measurable outcome that indicates success]
- [Criterion 3: Measurable outcome that indicates success]

**Secondary Success Indicators:**
- [Criterion 1: Nice-to-have outcome]
- [Criterion 2: Nice-to-have outcome]

## Evaluation Framework
### Technical Evaluation Criteria
- **Functionality:** [How well it solves the core problem - Weight: X%]
- **Performance:** [Speed, efficiency, resource usage - Weight: X%]
- **Integration:** [Ease of integration with current systems - Weight: X%]
- **Maturity:** [Stability, documentation, community - Weight: X%]

### Organizational Evaluation Criteria
- **Learning Curve:** [Time to competency for team - Weight: X%]
- **Operational Overhead:** [Maintenance and support requirements - Weight: X%]
- **Vendor Ecosystem:** [Support, roadmap, community health - Weight: X%]

### Business Evaluation Criteria
- **Total Cost:** [Licensing, implementation, operational costs - Weight: X%]
- **Risk Profile:** [Vendor, technical, operational risks - Weight: X%]
- **Strategic Alignment:** [Fit with technology strategy - Weight: X%]
```

**Quality Criteria:**
- Requirements are specific and testable
- Constraints are realistic and comprehensive
- Success criteria are measurable and time-bound
- Evaluation framework enables objective comparison
```

### Follow-up AI Prompts

**Requirements Deep-Dive:**
```markdown
**Context:** Refine the requirements analysis for [TECHNOLOGY_CATEGORY] evaluation.

**Current Requirements:** [COPY_FUNCTIONAL_AND_NON_FUNCTIONAL_REQUIREMENTS]

**Deep Analysis Needed:**
- Break down high-level requirements into specific, testable criteria
- Identify potential requirement conflicts or trade-offs
- Suggest validation approaches for each requirement
- Flag requirements that might be difficult to assess

**Output:** Detailed requirements specification with validation approaches and priority levels.
```

**Evaluation Criteria Weighting:**
```markdown
**Context:** Help prioritize and weight the evaluation criteria for [TECHNOLOGY_CATEGORY].

**Evaluation Criteria:** [COPY_EVALUATION_FRAMEWORK]
**Business Context:** [COMPANY_PRIORITIES_AND_CONSTRAINTS]

**Weighting Analysis:**
- Suggest appropriate weights for each criterion based on business context
- Identify potential conflicts between criteria
- Recommend evaluation methods for subjective criteria
- Suggest scoring scales and validation approaches

**Output:** Weighted evaluation matrix with scoring methodology.
```

## Generated Tasks (AI-Created)

1. **Problem Articulation and Validation**
   - Document current pain points with specific examples
   - Quantify impact of current limitations
   - Validate problem scope with stakeholders

2. **Requirements Gathering and Structuring**
   - Define functional requirements with acceptance criteria
   - Specify non-functional requirements with measurable targets
   - Document integration and compatibility requirements

3. **Constraint Analysis and Documentation**
   - Identify technical constraints and dependencies
   - Assess organizational capacity and capability constraints
   - Document business constraints including budget and timeline

4. **Success Criteria Definition**
   - Define measurable success indicators
   - Establish baseline metrics for comparison
   - Create validation approaches for success criteria

5. **Evaluation Framework Development**
   - Create weighted evaluation criteria matrix
   - Define scoring methodology and scales
   - Establish decision thresholds and processes

## Deliverables

### 1. Technology Requirements Specification
```yaml
## Technology Evaluation Context
**Technology Category:** [Database, Framework, Infrastructure Tool, etc.]
**Evaluation Trigger:** [What prompted this evaluation]
**Business Context:** [Company, team, project context]
**Timeline:** [Evaluation duration and decision deadline]

## Problem Definition
**Current State:** [Description of existing solution and limitations]
**Desired State:** [Vision of improved solution and capabilities]
**Problem Impact:** [Business or technical consequences of status quo]
**Success Vision:** [What success looks like after adoption]

## Functional Requirements
### Core Functionality
- [Requirement 1]: [Specific capability with acceptance criteria]
- [Requirement 2]: [Specific capability with acceptance criteria]
- [Requirement 3]: [Specific capability with acceptance criteria]

### Integration Requirements
- **Data Integration:** [How it connects with data sources/sinks]
- **System Integration:** [How it connects with other systems]
- **API Requirements:** [Interface and protocol specifications]
- **Security Integration:** [Authentication, authorization, compliance]

### User Experience Requirements
- **Developer Experience:** [API usability, tooling, documentation]
- **Operational Experience:** [Monitoring, debugging, maintenance]
- **End User Experience:** [Performance, reliability, functionality]

## Non-Functional Requirements
### Performance Requirements
- **Throughput:** [Requests/transactions per second]
- **Latency:** [Response time requirements]
- **Scalability:** [Growth capacity and scaling characteristics]
- **Resource Usage:** [CPU, memory, storage efficiency]

### Reliability Requirements
- **Availability:** [Uptime requirements and SLA expectations]
- **Fault Tolerance:** [Error handling and recovery capabilities]
- **Data Consistency:** [ACID properties, eventual consistency needs]
- **Backup/Recovery:** [Data protection and disaster recovery]

### Security Requirements
- **Data Protection:** [Encryption, privacy, compliance needs]
- **Access Control:** [Authentication, authorization, audit trails]
- **Network Security:** [TLS, VPN, firewall integration]
- **Compliance:** [Regulatory requirements and standards]

## Constraints Analysis
### Technical Constraints
- **Platform Constraints:** [Operating system, cloud provider, architecture]
- **Integration Constraints:** [Existing systems, data formats, protocols]
- **Performance Constraints:** [Hardware limitations, network constraints]
- **Security Constraints:** [Compliance requirements, security policies]

### Organizational Constraints  
- **Skill Constraints:** [Team expertise, learning capacity, training availability]
- **Resource Constraints:** [Team size, available time, support capacity]
- **Process Constraints:** [Development workflow, deployment process, approval gates]
- **Cultural Constraints:** [Technology preferences, risk tolerance, change management]

### Business Constraints
- **Budget Constraints:** [Licensing costs, implementation budget, operational costs]
- **Timeline Constraints:** [Decision deadline, implementation timeline, business milestones]
- **Strategic Constraints:** [Technology strategy, vendor relationships, long-term goals]
- **Risk Constraints:** [Risk tolerance, compliance requirements, business continuity]

## Success Criteria and Metrics
### Primary Success Indicators
- [Metric 1]: [Specific, measurable outcome with target and timeline]
- [Metric 2]: [Specific, measurable outcome with target and timeline]
- [Metric 3]: [Specific, measurable outcome with target and timeline]

### Secondary Success Indicators
- [Metric 1]: [Nice-to-have outcome with measurement approach]
- [Metric 2]: [Nice-to-have outcome with measurement approach]

### Baseline Measurements
- [Current Metric 1]: [Current state measurement for comparison]
- [Current Metric 2]: [Current state measurement for comparison]

## Evaluation Framework
### Evaluation Criteria Matrix
| Criterion | Weight | Description | Measurement Approach |
|-----------|--------|-------------|---------------------|
| Functionality | X% | How well it solves core problem | Feature checklist, capability testing |
| Performance | X% | Speed, efficiency, scalability | Benchmarking, load testing |
| Integration | X% | Ease of integration | Proof of concept, API testing |
| Maturity | X% | Stability, documentation, support | Community analysis, documentation review |
| Learning Curve | X% | Time to team competency | Prototype development, skill assessment |
| Total Cost | X% | All costs over 3-year period | Cost modeling, vendor quotes |
| Risk Profile | X% | Technical and business risks | Risk assessment, mitigation analysis |

### Scoring Methodology
**Scale:** [1-5, 1-10, or custom scale with definitions]
**Scoring Approach:** [How to assign scores objectively]
**Decision Thresholds:** [Minimum scores for adoption recommendation]

### Validation Approaches
- **Technical Validation:** [How to test technical capabilities]
- **Integration Validation:** [How to test integration feasibility]
- **Performance Validation:** [How to measure performance characteristics]
- **Usability Validation:** [How to assess developer/user experience]
```

### 2. Evaluation Execution Plan
```yaml
## Evaluation Methodology
**Evaluation Approach:** [Hands-on testing, research, expert interviews, etc.]
**Validation Strategy:** [How to test each requirement and criterion]
**Decision Process:** [How final recommendation will be made]
**Stakeholder Involvement:** [Who needs to review and approve]

## Stage Planning
### Stage 2: Landscape Investigation
- **Objective:** [Technology landscape analysis and shortlisting]
- **Duration:** [Time allocation]
- **Deliverables:** [Technology comparison matrix, shortlist]
- **Success Criteria:** [How to know this stage is complete]

### Stage 3: Hands-On Evaluation  
- **Objective:** [Practical testing and validation]
- **Duration:** [Time allocation]
- **Deliverables:** [Testing results, integration experiments]
- **Success Criteria:** [Evidence gathered for decision making]

### Stage 4: Decision Planning
- **Objective:** [Comparative analysis and recommendation]
- **Duration:** [Time allocation]
- **Deliverables:** [Decision matrix, risk assessment, recommendation]
- **Success Criteria:** [Clear adoption recommendation with rationale]

### Stage 5: Implementation Roadmap
- **Objective:** [Adoption planning and change management]
- **Duration:** [Time allocation]
- **Deliverables:** [Implementation plan, timeline, resource requirements]
- **Success Criteria:** [Actionable roadmap for technology adoption]

## Risk Assessment
### Evaluation Risks
- **Risk 1:** [Risk to evaluation process and mitigation]
- **Risk 2:** [Risk to evaluation process and mitigation]

### Technology Adoption Risks
- **Risk 1:** [Potential adoption risk and assessment approach]
- **Risk 2:** [Potential adoption risk and assessment approach]
```

## Validation Checkpoints

### AI Self-Assessment Checklist
- [ ] Problem statement is specific and clearly articulated
- [ ] Requirements are testable and include acceptance criteria
- [ ] Constraints are comprehensive and realistic
- [ ] Success criteria are measurable with defined baselines
- [ ] Evaluation framework enables objective comparison
- [ ] Weighting reflects business priorities and context

### Human Review Checklist
- [ ] **Problem Clarity:** Problem aligns with business needs and stakeholder understanding
- [ ] **Requirements Completeness:** All critical requirements captured without excessive scope
- [ ] **Constraint Realism:** Constraints accurately reflect organizational and technical reality
- [ ] **Success Measurability:** Success criteria can be objectively validated
- [ ] **Evaluation Practicality:** Framework can be executed within timeline and resource constraints

### Stakeholder Validation
- [ ] **Business Alignment:** Requirements and success criteria align with business objectives
- [ ] **Technical Feasibility:** Requirements are technically achievable within constraints
- [ ] **Resource Availability:** Evaluation plan is executable with available time and people
- [ ] **Decision Authority:** Clear understanding of who makes final adoption decision

## Exit Criteria
- [ ] Clear, specific problem statement validated by stakeholders
- [ ] Comprehensive requirements specification with measurable criteria
- [ ] Realistic constraints analysis covering technical, organizational, and business factors
- [ ] Objective evaluation framework with appropriate weighting
- [ ] Execution plan for remaining evaluation stages
- [ ] Success criteria and baseline metrics established

---

# Stage 2: Landscape Investigation
**Duration:** 2-4 hours  
**AI Persona:** Technology Scout  
**Primary Goal:** Analyze technology landscape and create shortlist of candidates for detailed evaluation

## Entry Criteria
- [ ] Stage 1 completed with clear requirements and evaluation criteria
- [ ] Technology category and problem space well-defined
- [ ] Evaluation framework established with weighted criteria
- [ ] Stakeholder alignment on evaluation approach

## High-Level Objective
Research the technology landscape, identify viable alternatives, and create a shortlist of 2-4 technologies for hands-on evaluation based on requirements fit and strategic considerations.

## AI Collaboration Pattern: High-Autonomy Research with Human Strategic Validation

### Primary AI Prompt
```markdown
**Role:** You are a senior technology scout and market analyst with deep knowledge of technology ecosystems and adoption trends.

**Context:** 
- Technology Category: [CATEGORY_FROM_STAGE_1]
- Problem Statement: [CORE_PROBLEM_FROM_STAGE_1]
- Requirements: [KEY_FUNCTIONAL_AND_NON_FUNCTIONAL_REQUIREMENTS]
- Constraints: [MAJOR_TECHNICAL_AND_BUSINESS_CONSTRAINTS]
- Evaluation Criteria: [WEIGHTED_EVALUATION_FRAMEWORK]

**Task:** Conduct comprehensive technology landscape analysis and create shortlist for evaluation.

**Research Framework:**
1. **Market Landscape:** Current technology options and market positioning
2. **Technology Analysis:** Capabilities, maturity, and differentiation
3. **Ecosystem Assessment:** Vendor health, community, and support
4. **Fit Analysis:** Alignment with requirements and constraints
5. **Shortlist Recommendation:** Top candidates for detailed evaluation

**Output Format:**
```
## Technology Landscape Overview
**Market Maturity:** [Emerging/Growing/Mature market characteristics]
**Key Trends:** [Important developments affecting technology category]
**Market Leaders:** [Dominant players and their positioning]
**Emerging Players:** [New entrants and innovative approaches]

## Technology Options Analysis
### Option 1: [Technology Name]
**Category:** [Open Source/Commercial/Enterprise/Cloud Service]
**Maturity:** [Early Stage/Growing/Mature/Legacy]
**Key Strengths:**
- [Strength 1: Specific capability or advantage]
- [Strength 2: Specific capability or advantage]
- [Strength 3: Specific capability or advantage]
**Key Weaknesses:**
- [Weakness 1: Specific limitation or concern]
- [Weakness 2: Specific limitation or concern]
**Use Cases:** [Primary scenarios where this technology excels]
**Ecosystem:** [Vendor/community health, support options, roadmap]

### Option 2: [Technology Name]
[Same format as Option 1]

### Option 3: [Technology Name]
[Same format as Option 1]

[Continue for all viable options]

## Requirements Fit Analysis
### Functional Requirements Fit
| Technology | Req 1 | Req 2 | Req 3 | Overall Functional Fit |
|------------|-------|-------|-------|----------------------|
| Option 1   | // | // | // | High/Medium/Low |
| Option 2   | // | // | // | High/Medium/Low |

### Non-Functional Requirements Fit
| Technology | Performance | Scalability | Security | Integration | Overall NFR Fit |
|------------|-------------|-------------|----------|-------------|-----------------|
| Option 1   | // | // | // | // | High/Medium/Low |

### Constraints Compatibility
| Technology | Technical Constraints | Org Constraints | Business Constraints | Overall Compatibility |
|------------|----------------------|-----------------|---------------------|----------------------|
| Option 1   | // | // | // | High/Medium/Low |

## Ecosystem and Vendor Analysis
### Vendor/Community Health Assessment
| Technology | Financial Health | Community Size | Documentation | Support Options | Roadmap Clarity |
|------------|------------------|----------------|---------------|-----------------|-----------------|
| Option 1   | Strong/Good/Weak | Large/Medium/Small | Excellent/Good/Poor | Multiple/Limited/None | Clear/Unclear/Unknown |

### Risk Assessment
| Technology | Vendor Risk | Technical Risk | Adoption Risk | Overall Risk |
|------------|-------------|----------------|---------------|--------------|
| Option 1   | Low/Med/High | Low/Med/High | Low/Med/High | Low/Med/High |

## Shortlist Recommendation
### Recommended for Detailed Evaluation
**Technology 1: [Name]**
- **Rationale:** [Why this deserves detailed evaluation]
- **Key Validation Areas:** [What to focus on during hands-on testing]
- **Expected Outcome:** [Likely result based on initial analysis]

**Technology 2: [Name]**
- **Rationale:** [Why this deserves detailed evaluation]
- **Key Validation Areas:** [What to focus on during hands-on testing]
- **Expected Outcome:** [Likely result based on initial analysis]

**Technology 3: [Name]** (if applicable)
- **Rationale:** [Why this deserves detailed evaluation]
- **Key Validation Areas:** [What to focus on during hands-on testing]
- **Expected Outcome:** [Likely result based on initial analysis]

### Excluded from Evaluation
**Technology X: [Name]** - [Reason for exclusion]
**Technology Y: [Name]** - [Reason for exclusion]

## Next Steps Recommendations
**Evaluation Priority Order:** [Which technology to evaluate first and why]
**Key Questions to Answer:** [Critical unknowns to resolve in Stage 3]
**Potential Red Flags:** [Warning signs to watch for during hands-on testing]
```

**Quality Criteria:**
- Comprehensive coverage of viable technology options
- Objective analysis based on stated requirements and constraints
- Clear rationale for inclusion/exclusion decisions
- Actionable recommendations for next stage
```

### Specialized Research Prompts

**Deep Competitive Analysis:**
```markdown
**Focus:** Deep dive comparison between top technology candidates.

**Technologies:** [TOP_2_3_CANDIDATES_FROM_INITIAL_ANALYSIS]
**Comparison Dimensions:** [SPECIFIC_REQUIREMENTS_AND_CRITERIA]

**Analysis Required:**
- Feature-by-feature comparison matrix
- Performance characteristics comparison
- Integration complexity assessment
- Total cost of ownership analysis
- Risk profile comparison

**Output:** Detailed competitive analysis matrix with recommendation priorities.
```

**Ecosystem Deep Dive:**
```markdown
**Focus:** Analyze vendor/community ecosystem health for shortlisted technologies.

**Assessment Areas:**
- Financial stability and business model sustainability
- Community engagement and contribution patterns
- Documentation quality and completeness
- Support options and response quality
- Product roadmap and strategic direction
- Integration partner ecosystem

**Output:** Ecosystem health scorecard with risk assessment for each candidate.
```

## Generated Tasks (AI-Created)

1. **Technology Landscape Research**
   - Identify all viable technology options in the category
   - Analyze market positioning and competitive dynamics
   - Research emerging trends and future developments

2. **Requirements Mapping**
   - Map each technology's capabilities to functional requirements
   - Assess non-functional requirements fit
   - Identify requirement gaps and potential workarounds

3. **Ecosystem Health Analysis**
   - Research vendor/community financial health and stability
   - Analyze documentation quality and community support
   - Assess product roadmap and strategic direction

4. **Constraint Compatibility Assessment**
   - Validate technical constraint compatibility
   - Assess organizational constraint alignment
   - Analyze business constraint implications

5. **Shortlist Development**
   - Apply evaluation criteria to create ranked list
   - Develop rationale for inclusion/exclusion decisions
   - Prioritize candidates for hands-on evaluation

## Deliverables

### 1. Technology Landscape Analysis
```yaml
## Market Overview
**Technology Category:** [Database, Framework, Infrastructure, etc.]
**Market Maturity:** [Description of market evolution and trends]
**Key Market Drivers:** [Forces shaping technology adoption]
**Future Outlook:** [Expected developments and timeline]

## Technology Inventory
### Commercial Solutions
- **[Technology 1]:** [Brief description, strengths, market position]
- **[Technology 2]:** [Brief description, strengths, market position]
- **[Technology 3]:** [Brief description, strengths, market position]

### Open Source Solutions
- **[Technology 1]:** [Brief description, community, governance model]
- **[Technology 2]:** [Brief description, community, governance model]

### Cloud/SaaS Solutions
- **[Technology 1]:** [Brief description, provider, service model]
- **[Technology 2]:** [Brief description, provider, service model]

### Emerging/Niche Solutions
- **[Technology 1]:** [Brief description, innovation, maturity level]
- **[Technology 2]:** [Brief description, innovation, maturity level]

## Detailed Technology Analysis
### [Technology Name 1]
**Overview:** [Purpose, target market, key value proposition]
**Technical Architecture:** [How it works, key technical approach]
**Key Features:**
- [Feature 1: Capability description and uniqueness]
- [Feature 2: Capability description and uniqueness]
- [Feature 3: Capability description and uniqueness]
**Strengths:**
- [Strength 1: Specific advantage with evidence]
- [Strength 2: Specific advantage with evidence]
**Weaknesses:**
- [Weakness 1: Specific limitation with impact]
- [Weakness 2: Specific limitation with impact]
**Use Cases:** [Primary scenarios and success stories]
**Ecosystem:** [Vendor health, community, partnerships, support]
**Pricing Model:** [Cost structure and licensing approach]
**Learning Curve:** [Complexity and skill requirements]

### [Technology Name 2]
[Same detailed format as above]

[Continue for all major options identified]

## Requirements Fit Assessment
### Functional Requirements Matrix
| Requirement | [Tech 1] | [Tech 2] | [Tech 3] | Notes |
|-------------|----------|----------|----------|-------|
| [Functional Req 1] |  Full/ Partial/ No | // | // | [Gap analysis] |
| [Functional Req 2] | // | // | // | [Gap analysis] |
| [Functional Req 3] | // | // | // | [Gap analysis] |

### Non-Functional Requirements Matrix
| Requirement | [Tech 1] | [Tech 2] | [Tech 3] | Validation Approach |
|-------------|----------|----------|----------|-------------------|
| Performance | // | // | // | [How to test] |
| Scalability | // | // | // | [How to test] |
| Security | // | // | // | [How to test] |
| Integration | // | // | // | [How to test] |

### Constraints Compatibility Matrix
| Constraint Type | [Tech 1] | [Tech 2] | [Tech 3] | Impact Assessment |
|-----------------|----------|----------|----------|-------------------|
| Technical | // | // | // | [Specific impacts] |
| Organizational | // | // | // | [Specific impacts] |
| Business | // | // | // | [Specific impacts] |
```

### 2. Technology Shortlist with Rationale
```yaml
## Evaluation Shortlist
### Primary Candidates (Recommended for Full Evaluation)

#### Candidate 1: [Technology Name]
**Overall Score:** [Weighted score based on evaluation criteria]
**Rationale for Inclusion:**
- [Reason 1: Strong fit with specific requirements]
- [Reason 2: Strategic advantages or opportunities]
- [Reason 3: Risk/benefit profile]

**Key Validation Priorities:**
- [Priority 1: Critical capability to validate through hands-on testing]
- [Priority 2: Integration or performance concern to resolve]
- [Priority 3: Organizational fit factor to assess]

**Expected Evaluation Outcome:** [Predicted result: ADOPT/TRIAL/AVOID with confidence level]

**Red Flags to Monitor:**
- [Flag 1: Specific concern to watch during evaluation]
- [Flag 2: Potential deal-breaker to validate]

#### Candidate 2: [Technology Name]
[Same format as Candidate 1]

#### Candidate 3: [Technology Name] (if applicable)
[Same format as Candidate 1]

### Secondary Candidates (Conditional Evaluation)
#### [Technology Name]
**Condition for Evaluation:** [Under what circumstances this should be evaluated]
**Key Differentiator:** [What makes this potentially valuable despite lower ranking]

### Excluded Technologies
#### [Technology Name] - [Exclusion Reason]
**Rationale:** [Specific reasons for exclusion]
**Reconsideration Triggers:** [What would change to make this viable]

#### [Technology Name] - [Exclusion Reason]
**Rationale:** [Specific reasons for exclusion]
**Reconsideration Triggers:** [What would change to make this viable]

## Evaluation Strategy
### Evaluation Order and Rationale
1. **[Technology Name]** - [Why to evaluate first]
2. **[Technology Name]** - [Why to evaluate second]
3. **[Technology Name]** - [Why to evaluate third, if needed]

### Comparative Evaluation Approach
**Head-to-Head Comparison:** [Whether to compare technologies directly or separately]
**Evaluation Scenarios:** [Common test scenarios to use across all candidates]
**Decision Framework:** [How to make final recommendation if multiple candidates are viable]

## Risk Assessment by Candidate
### [Technology Name 1]
**High Risks:**
- [Risk 1: Description, likelihood, impact, mitigation approach]
- [Risk 2: Description, likelihood, impact, mitigation approach]

**Medium Risks:**
- [Risk 1: Description and monitoring approach]
- [Risk 2: Description and monitoring approach]

**Risk Score:** [Overall risk assessment: Low/Medium/High]

### [Technology Name 2]
[Same risk format as above]

## Stage 3 Preparation
**Hands-On Testing Priorities:** [What to focus on during practical evaluation]
**Test Environment Requirements:** [Infrastructure and setup needs]
**Success Criteria for Stage 3:** [How to know hands-on evaluation is complete]
**Escalation Triggers:** [When to seek additional input or expand evaluation scope]
```

## Validation Checkpoints

### AI Self-Assessment Checklist
- [ ] Comprehensive coverage of technology landscape without obvious omissions
- [ ] Objective analysis based on stated requirements and constraints
- [ ] Clear rationale for shortlist inclusion/exclusion decisions
- [ ] Actionable guidance for hands-on evaluation stage
- [ ] Risk assessment covers major adoption concerns
- [ ] Evaluation priority order is logical and well-reasoned

### Human Review Checklist
- [ ] **Landscape Completeness:** No major technology options overlooked
- [ ] **Analysis Objectivity:** Assessment appears unbiased and evidence-based
- [ ] **Requirements Alignment:** Shortlist candidates genuinely fit requirements
- [ ] **Constraint Realism:** Constraint assessments reflect actual organizational reality
- [ ] **Evaluation Feasibility:** Shortlist is manageable for available time and resources

### Strategic Validation
- [ ] **Business Alignment:** Shortlisted technologies align with strategic direction
- [ ] **Risk Tolerance:** Risk profiles of candidates match organizational appetite
- [ ] **Resource Requirements:** Evaluation plan is executable with available capacity
- [ ] **Decision Timeline:** Evaluation approach supports required decision timeline

## Exit Criteria
- [ ] Comprehensive technology landscape analysis completed
- [ ] Requirements fit assessment completed for all viable options
- [ ] Technology shortlist of 2-4 candidates with clear rationale
- [ ] Risk assessment completed for each shortlisted candidate
- [ ] Evaluation strategy and priorities defined for Stage 3
- [ ] Stakeholder validation of shortlist and evaluation approach

---

# Stage 3: Hands-On Evaluation
**Duration:** 4-8 hours  
**AI Persona:** Technical Advisor  
**Primary Goal:** Conduct practical testing and integration experiments to validate technology capabilities and organizational fit

## Entry Criteria
- [ ] Stage 2 completed with validated technology shortlist
- [ ] Evaluation priorities and test scenarios defined
- [ ] Test environment access and setup requirements identified
- [ ] Validation criteria and success metrics established

## High-Level Objective
Move beyond research to hands-on experience with shortlisted technologies through practical testing, integration experiments, and real-world scenario validation.
